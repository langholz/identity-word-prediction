Loaded corpus from 'ptb_char_corpus.pkl'...
['<eos>', 'N', '<unk>', 'a', 'e', 'r', ' ', 'b', 'n', 'k', 'o', 't', 'l', 'i', 'z', 'c', 'w', 'y', 'u', 's', 'f', 'm', 'g', 'h', 'd', '-', 'q', 'p', 'x', 'j', 'v', '.', "'", '1', '9', '5', '0', '&', '$', '3', '2', '4', '8', '6', '7', '#', '\\', '/', '*']

[batch =  100] train_perplexity =   101.39, train_loss =  4.62, learning_rate = 20.00000000


[batch =  200] train_perplexity =    29.11, train_loss =  3.37, learning_rate = 20.00000000


[batch =  300] train_perplexity =    15.87, train_loss =  2.76, learning_rate = 20.00000000


[batch =  400] train_perplexity =    10.52, train_loss =  2.35, learning_rate = 20.00000000


[batch =  500] train_perplexity =     8.25, train_loss =  2.11, learning_rate = 20.00000000


[batch =  600] train_perplexity =     7.26, train_loss =  1.98, learning_rate = 20.00000000


[batch =  700] train_perplexity =     6.77, train_loss =  1.91, learning_rate = 20.00000000


[batch =  800] train_perplexity =     6.93, train_loss =  1.94, learning_rate = 20.00000000


[batch =  900] train_perplexity =     6.81, train_loss =  1.92, learning_rate = 20.00000000


[batch = 1000] train_perplexity =     6.98, train_loss =  1.94, learning_rate = 20.00000000


[batch = 1100] train_perplexity =     6.91, train_loss =  1.93, learning_rate = 20.00000000


[batch = 1200] train_perplexity =     6.75, train_loss =  1.91, learning_rate = 20.00000000


[batch = 1300] train_perplexity =     6.70, train_loss =  1.90, learning_rate = 20.00000000


[batch = 1400] train_perplexity =     6.67, train_loss =  1.90, learning_rate = 20.00000000


[batch = 1500] train_perplexity =     6.58, train_loss =  1.88, learning_rate = 20.00000000


[batch = 1600] train_perplexity =     6.63, train_loss =  1.89, learning_rate = 20.00000000


[batch = 1700] train_perplexity =     6.61, train_loss =  1.89, learning_rate = 20.00000000


[batch = 1800] train_perplexity =     6.61, train_loss =  1.89, learning_rate = 20.00000000


[batch = 1900] train_perplexity =     6.76, train_loss =  1.91, learning_rate = 20.00000000


[batch = 2000] train_perplexity =     6.92, train_loss =  1.93, learning_rate = 20.00000000


[batch = 2100] train_perplexity =     6.70, train_loss =  1.90, learning_rate = 20.00000000


[batch = 2200] train_perplexity =     6.83, train_loss =  1.92, learning_rate = 20.00000000


[batch = 2300] train_perplexity =     7.06, train_loss =  1.95, learning_rate = 20.00000000


[batch = 2400] train_perplexity =     6.88, train_loss =  1.93, learning_rate = 20.00000000


[batch = 2500] train_perplexity =     6.97, train_loss =  1.94, learning_rate = 20.00000000


[batch = 2600] train_perplexity =     7.05, train_loss =  1.95, learning_rate = 20.00000000


[batch = 2700] train_perplexity =     7.04, train_loss =  1.95, learning_rate = 20.00000000


[batch = 2800] train_perplexity =     6.92, train_loss =  1.93, learning_rate = 20.00000000


[batch = 2900] train_perplexity =     7.02, train_loss =  1.95, learning_rate = 20.00000000


[batch = 3000] train_perplexity =     6.81, train_loss =  1.92, learning_rate = 20.00000000


[batch = 3100] train_perplexity =     7.20, train_loss =  1.97, learning_rate = 20.00000000


[batch = 3200] train_perplexity =     7.29, train_loss =  1.99, learning_rate = 20.00000000


[batch = 3300] train_perplexity =     7.19, train_loss =  1.97, learning_rate = 20.00000000


[batch = 3400] train_perplexity =     7.02, train_loss =  1.95, learning_rate = 20.00000000


[batch = 3500] train_perplexity =     7.10, train_loss =  1.96, learning_rate = 20.00000000


[batch = 3600] train_perplexity =     7.23, train_loss =  1.98, learning_rate = 20.00000000


[batch = 3700] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 20.00000000


[batch = 3800] train_perplexity =     7.43, train_loss =  2.01, learning_rate = 20.00000000


[batch = 3900] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 20.00000000


[batch = 4000] train_perplexity =     7.95, train_loss =  2.07, learning_rate = 20.00000000


[batch = 4100] train_perplexity =    12.79, train_loss =  2.55, learning_rate = 20.00000000


[batch = 4200] train_perplexity =    56.92, train_loss =  4.04, learning_rate = 20.00000000


[batch = 4300] train_perplexity =    67.71, train_loss =  4.22, learning_rate = 20.00000000


[batch = 4400] train_perplexity =    24.74, train_loss =  3.21, learning_rate = 20.00000000


[batch = 4500] train_perplexity =    19.20, train_loss =  2.95, learning_rate = 20.00000000


[batch = 4600] train_perplexity =    19.51, train_loss =  2.97, learning_rate = 20.00000000


[batch = 4700] train_perplexity =    19.09, train_loss =  2.95, learning_rate = 20.00000000


[batch = 4800] train_perplexity =    18.28, train_loss =  2.91, learning_rate = 20.00000000


[batch = 4900] train_perplexity =    17.08, train_loss =  2.84, learning_rate = 20.00000000


[batch = 5000] train_perplexity =    18.63, train_loss =  2.92, learning_rate = 20.00000000


[batch = 5100] train_perplexity =    16.95, train_loss =  2.83, learning_rate = 20.00000000


[batch = 5200] train_perplexity =    16.90, train_loss =  2.83, learning_rate = 20.00000000


[batch = 5300] train_perplexity =    17.34, train_loss =  2.85, learning_rate = 20.00000000


[batch = 5400] train_perplexity =    17.42, train_loss =  2.86, learning_rate = 20.00000000


[batch = 5500] train_perplexity =    17.50, train_loss =  2.86, learning_rate = 20.00000000


[batch = 5600] train_perplexity =    19.49, train_loss =  2.97, learning_rate = 20.00000000


[batch = 5700] train_perplexity =    19.67, train_loss =  2.98, learning_rate = 20.00000000


[batch = 5800] train_perplexity =    18.03, train_loss =  2.89, learning_rate = 20.00000000


[batch = 5900] train_perplexity =    18.53, train_loss =  2.92, learning_rate = 20.00000000


[batch = 6000] train_perplexity =    17.89, train_loss =  2.88, learning_rate = 20.00000000


[batch = 6100] train_perplexity =    18.54, train_loss =  2.92, learning_rate = 20.00000000


[batch = 6200] train_perplexity =    18.25, train_loss =  2.90, learning_rate = 20.00000000


[batch = 6300] train_perplexity =    17.93, train_loss =  2.89, learning_rate = 20.00000000


[batch = 6400] train_perplexity =    18.27, train_loss =  2.91, learning_rate = 20.00000000


[batch = 6500] train_perplexity =    18.71, train_loss =  2.93, learning_rate = 20.00000000


[batch = 6600] train_perplexity =    19.34, train_loss =  2.96, learning_rate = 20.00000000


[batch = 6700] train_perplexity =    19.30, train_loss =  2.96, learning_rate = 20.00000000


[batch = 6800] train_perplexity =    18.67, train_loss =  2.93, learning_rate = 20.00000000


[batch = 6900] train_perplexity =    18.92, train_loss =  2.94, learning_rate = 20.00000000


[epoch =   1] validation_perplexity =    15.55, validation_loss =  2.74

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   1] min_validation_perplexity =    15.55, min_validation_loss =  2.74


[batch =  100] train_perplexity =    18.21, train_loss =  2.90, learning_rate = 20.00000000


[batch =  200] train_perplexity =    18.95, train_loss =  2.94, learning_rate = 20.00000000


[batch =  300] train_perplexity =    19.31, train_loss =  2.96, learning_rate = 20.00000000


[batch =  400] train_perplexity =    19.87, train_loss =  2.99, learning_rate = 20.00000000


[batch =  500] train_perplexity =    19.67, train_loss =  2.98, learning_rate = 20.00000000


[batch =  600] train_perplexity =    18.97, train_loss =  2.94, learning_rate = 20.00000000


[batch =  700] train_perplexity =    19.56, train_loss =  2.97, learning_rate = 20.00000000


[batch =  800] train_perplexity =    20.20, train_loss =  3.01, learning_rate = 20.00000000


[batch =  900] train_perplexity =    19.86, train_loss =  2.99, learning_rate = 20.00000000


[batch = 1000] train_perplexity =    19.35, train_loss =  2.96, learning_rate = 20.00000000


[batch = 1100] train_perplexity =    20.31, train_loss =  3.01, learning_rate = 20.00000000


[batch = 1200] train_perplexity =    19.26, train_loss =  2.96, learning_rate = 20.00000000


[batch = 1300] train_perplexity =    17.83, train_loss =  2.88, learning_rate = 20.00000000


[batch = 1400] train_perplexity =    20.38, train_loss =  3.01, learning_rate = 20.00000000


[batch = 1500] train_perplexity =    18.60, train_loss =  2.92, learning_rate = 20.00000000


[batch = 1600] train_perplexity =    19.61, train_loss =  2.98, learning_rate = 20.00000000


[batch = 1700] train_perplexity =    19.88, train_loss =  2.99, learning_rate = 20.00000000


[batch = 1800] train_perplexity =    20.55, train_loss =  3.02, learning_rate = 20.00000000


[batch = 1900] train_perplexity =    20.77, train_loss =  3.03, learning_rate = 20.00000000


[batch = 2000] train_perplexity =    22.51, train_loss =  3.11, learning_rate = 20.00000000


[batch = 2100] train_perplexity =    21.47, train_loss =  3.07, learning_rate = 20.00000000


[batch = 2200] train_perplexity =    20.82, train_loss =  3.04, learning_rate = 20.00000000


[batch = 2300] train_perplexity =    21.07, train_loss =  3.05, learning_rate = 20.00000000


[batch = 2400] train_perplexity =    21.14, train_loss =  3.05, learning_rate = 20.00000000


[batch = 2500] train_perplexity =    20.60, train_loss =  3.03, learning_rate = 20.00000000


[batch = 2600] train_perplexity =    21.13, train_loss =  3.05, learning_rate = 20.00000000


[batch = 2700] train_perplexity =    21.04, train_loss =  3.05, learning_rate = 20.00000000


[batch = 2800] train_perplexity =    20.52, train_loss =  3.02, learning_rate = 20.00000000


[batch = 2900] train_perplexity =    19.88, train_loss =  2.99, learning_rate = 20.00000000


[batch = 3000] train_perplexity =    18.29, train_loss =  2.91, learning_rate = 20.00000000


[batch = 3100] train_perplexity =    18.88, train_loss =  2.94, learning_rate = 20.00000000


[batch = 3200] train_perplexity =    19.46, train_loss =  2.97, learning_rate = 20.00000000


[batch = 3300] train_perplexity =    20.68, train_loss =  3.03, learning_rate = 20.00000000


[batch = 3400] train_perplexity =    19.55, train_loss =  2.97, learning_rate = 20.00000000


[batch = 3500] train_perplexity =    19.61, train_loss =  2.98, learning_rate = 20.00000000


[batch = 3600] train_perplexity =    20.06, train_loss =  3.00, learning_rate = 20.00000000


[batch = 3700] train_perplexity =    19.69, train_loss =  2.98, learning_rate = 20.00000000


[batch = 3800] train_perplexity =    19.93, train_loss =  2.99, learning_rate = 20.00000000


[batch = 3900] train_perplexity =    21.72, train_loss =  3.08, learning_rate = 20.00000000


[batch = 4000] train_perplexity =    22.04, train_loss =  3.09, learning_rate = 20.00000000


[batch = 4100] train_perplexity =    20.42, train_loss =  3.02, learning_rate = 20.00000000


[batch = 4200] train_perplexity =    20.64, train_loss =  3.03, learning_rate = 20.00000000


[batch = 4300] train_perplexity =    19.96, train_loss =  2.99, learning_rate = 20.00000000


[batch = 4400] train_perplexity =    20.94, train_loss =  3.04, learning_rate = 20.00000000


[batch = 4500] train_perplexity =    20.94, train_loss =  3.04, learning_rate = 20.00000000


[batch = 4600] train_perplexity =    23.46, train_loss =  3.16, learning_rate = 20.00000000


[batch = 4700] train_perplexity =    22.65, train_loss =  3.12, learning_rate = 20.00000000


[batch = 4800] train_perplexity =    23.12, train_loss =  3.14, learning_rate = 20.00000000


[batch = 4900] train_perplexity =    23.93, train_loss =  3.17, learning_rate = 20.00000000


[batch = 5000] train_perplexity =    22.41, train_loss =  3.11, learning_rate = 20.00000000


[batch = 5100] train_perplexity =    21.42, train_loss =  3.06, learning_rate = 20.00000000


[batch = 5200] train_perplexity =    21.81, train_loss =  3.08, learning_rate = 20.00000000


[batch = 5300] train_perplexity =    22.44, train_loss =  3.11, learning_rate = 20.00000000


[batch = 5400] train_perplexity =    22.24, train_loss =  3.10, learning_rate = 20.00000000


[batch = 5500] train_perplexity =    23.28, train_loss =  3.15, learning_rate = 20.00000000


[batch = 5600] train_perplexity =    22.69, train_loss =  3.12, learning_rate = 20.00000000


[batch = 5700] train_perplexity =    24.40, train_loss =  3.19, learning_rate = 20.00000000


[batch = 5800] train_perplexity =    24.16, train_loss =  3.18, learning_rate = 20.00000000


[batch = 5900] train_perplexity =    24.29, train_loss =  3.19, learning_rate = 20.00000000


[batch = 6000] train_perplexity =    21.22, train_loss =  3.05, learning_rate = 20.00000000


[batch = 6100] train_perplexity =    21.36, train_loss =  3.06, learning_rate = 20.00000000


[batch = 6200] train_perplexity =    22.03, train_loss =  3.09, learning_rate = 20.00000000


[batch = 6300] train_perplexity =    20.98, train_loss =  3.04, learning_rate = 20.00000000


[batch = 6400] train_perplexity =    22.22, train_loss =  3.10, learning_rate = 20.00000000


[batch = 6500] train_perplexity =    23.49, train_loss =  3.16, learning_rate = 20.00000000


[batch = 6600] train_perplexity =    22.64, train_loss =  3.12, learning_rate = 20.00000000


[batch = 6700] train_perplexity =    21.80, train_loss =  3.08, learning_rate = 20.00000000


[batch = 6800] train_perplexity =    22.54, train_loss =  3.12, learning_rate = 20.00000000


[batch = 6900] train_perplexity =    22.45, train_loss =  3.11, learning_rate = 20.00000000


[epoch =   2] validation_perplexity =    26.80, validation_loss =  3.29

[epoch =   2] annealing learning_rate = 5.00000000

[batch =  100] train_perplexity =    13.88, train_loss =  2.63, learning_rate = 5.00000000


[batch =  200] train_perplexity =    12.91, train_loss =  2.56, learning_rate = 5.00000000


[batch =  300] train_perplexity =    12.66, train_loss =  2.54, learning_rate = 5.00000000


[batch =  400] train_perplexity =    13.02, train_loss =  2.57, learning_rate = 5.00000000


[batch =  500] train_perplexity =    12.94, train_loss =  2.56, learning_rate = 5.00000000


[batch =  600] train_perplexity =    12.74, train_loss =  2.54, learning_rate = 5.00000000


[batch =  700] train_perplexity =    12.65, train_loss =  2.54, learning_rate = 5.00000000


[batch =  800] train_perplexity =    12.74, train_loss =  2.54, learning_rate = 5.00000000


[batch =  900] train_perplexity =    12.56, train_loss =  2.53, learning_rate = 5.00000000


[batch = 1000] train_perplexity =    12.42, train_loss =  2.52, learning_rate = 5.00000000


[batch = 1100] train_perplexity =    12.56, train_loss =  2.53, learning_rate = 5.00000000


[batch = 1200] train_perplexity =    12.34, train_loss =  2.51, learning_rate = 5.00000000


[batch = 1300] train_perplexity =    12.19, train_loss =  2.50, learning_rate = 5.00000000


[batch = 1400] train_perplexity =    12.27, train_loss =  2.51, learning_rate = 5.00000000


[batch = 1500] train_perplexity =    11.93, train_loss =  2.48, learning_rate = 5.00000000


[batch = 1600] train_perplexity =    12.11, train_loss =  2.49, learning_rate = 5.00000000


[batch = 1700] train_perplexity =    12.00, train_loss =  2.48, learning_rate = 5.00000000


[batch = 1800] train_perplexity =    11.97, train_loss =  2.48, learning_rate = 5.00000000


[batch = 1900] train_perplexity =    12.24, train_loss =  2.51, learning_rate = 5.00000000


[batch = 2000] train_perplexity =    12.29, train_loss =  2.51, learning_rate = 5.00000000


[batch = 2100] train_perplexity =    12.10, train_loss =  2.49, learning_rate = 5.00000000


[batch = 2200] train_perplexity =    12.08, train_loss =  2.49, learning_rate = 5.00000000


[batch = 2300] train_perplexity =    12.01, train_loss =  2.49, learning_rate = 5.00000000


[batch = 2400] train_perplexity =    11.94, train_loss =  2.48, learning_rate = 5.00000000


[batch = 2500] train_perplexity =    11.85, train_loss =  2.47, learning_rate = 5.00000000


[batch = 2600] train_perplexity =    11.84, train_loss =  2.47, learning_rate = 5.00000000


[batch = 2700] train_perplexity =    11.86, train_loss =  2.47, learning_rate = 5.00000000


[batch = 2800] train_perplexity =    11.74, train_loss =  2.46, learning_rate = 5.00000000


[batch = 2900] train_perplexity =    11.64, train_loss =  2.45, learning_rate = 5.00000000


[batch = 3000] train_perplexity =    11.57, train_loss =  2.45, learning_rate = 5.00000000


[batch = 3100] train_perplexity =    11.76, train_loss =  2.46, learning_rate = 5.00000000


[batch = 3200] train_perplexity =    11.73, train_loss =  2.46, learning_rate = 5.00000000


[batch = 3300] train_perplexity =    11.65, train_loss =  2.46, learning_rate = 5.00000000


[batch = 3400] train_perplexity =    11.63, train_loss =  2.45, learning_rate = 5.00000000


[batch = 3500] train_perplexity =    11.48, train_loss =  2.44, learning_rate = 5.00000000


[batch = 3600] train_perplexity =    11.58, train_loss =  2.45, learning_rate = 5.00000000


[batch = 3700] train_perplexity =    11.53, train_loss =  2.45, learning_rate = 5.00000000


[batch = 3800] train_perplexity =    11.50, train_loss =  2.44, learning_rate = 5.00000000


[batch = 3900] train_perplexity =    11.37, train_loss =  2.43, learning_rate = 5.00000000


[batch = 4000] train_perplexity =    11.56, train_loss =  2.45, learning_rate = 5.00000000


[batch = 4100] train_perplexity =    11.43, train_loss =  2.44, learning_rate = 5.00000000


[batch = 4200] train_perplexity =    11.51, train_loss =  2.44, learning_rate = 5.00000000


[batch = 4300] train_perplexity =    11.47, train_loss =  2.44, learning_rate = 5.00000000


[batch = 4400] train_perplexity =    11.50, train_loss =  2.44, learning_rate = 5.00000000


[batch = 4500] train_perplexity =    11.25, train_loss =  2.42, learning_rate = 5.00000000


[batch = 4600] train_perplexity =    11.45, train_loss =  2.44, learning_rate = 5.00000000


[batch = 4700] train_perplexity =    11.43, train_loss =  2.44, learning_rate = 5.00000000


[batch = 4800] train_perplexity =    11.13, train_loss =  2.41, learning_rate = 5.00000000


[batch = 4900] train_perplexity =    11.35, train_loss =  2.43, learning_rate = 5.00000000


[batch = 5000] train_perplexity =    11.33, train_loss =  2.43, learning_rate = 5.00000000


[batch = 5100] train_perplexity =    11.25, train_loss =  2.42, learning_rate = 5.00000000


[batch = 5200] train_perplexity =    11.45, train_loss =  2.44, learning_rate = 5.00000000


[batch = 5300] train_perplexity =    11.37, train_loss =  2.43, learning_rate = 5.00000000


[batch = 5400] train_perplexity =    10.86, train_loss =  2.39, learning_rate = 5.00000000


[batch = 5500] train_perplexity =    10.98, train_loss =  2.40, learning_rate = 5.00000000


[batch = 5600] train_perplexity =    11.18, train_loss =  2.41, learning_rate = 5.00000000


[batch = 5700] train_perplexity =    11.09, train_loss =  2.41, learning_rate = 5.00000000


[batch = 5800] train_perplexity =    11.19, train_loss =  2.41, learning_rate = 5.00000000


[batch = 5900] train_perplexity =    11.21, train_loss =  2.42, learning_rate = 5.00000000


[batch = 6000] train_perplexity =    11.03, train_loss =  2.40, learning_rate = 5.00000000


[batch = 6100] train_perplexity =    11.06, train_loss =  2.40, learning_rate = 5.00000000


[batch = 6200] train_perplexity =    10.98, train_loss =  2.40, learning_rate = 5.00000000


[batch = 6300] train_perplexity =    10.88, train_loss =  2.39, learning_rate = 5.00000000


[batch = 6400] train_perplexity =    10.95, train_loss =  2.39, learning_rate = 5.00000000


[batch = 6500] train_perplexity =    10.91, train_loss =  2.39, learning_rate = 5.00000000


[batch = 6600] train_perplexity =    11.21, train_loss =  2.42, learning_rate = 5.00000000


[batch = 6700] train_perplexity =    11.06, train_loss =  2.40, learning_rate = 5.00000000


[batch = 6800] train_perplexity =    11.00, train_loss =  2.40, learning_rate = 5.00000000


[batch = 6900] train_perplexity =    10.94, train_loss =  2.39, learning_rate = 5.00000000


[epoch =   3] validation_perplexity =     9.53, validation_loss =  2.25

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   3] min_validation_perplexity =     9.53, min_validation_loss =  2.25


[batch =  100] train_perplexity =    10.93, train_loss =  2.39, learning_rate = 5.00000000


[batch =  200] train_perplexity =    10.50, train_loss =  2.35, learning_rate = 5.00000000


[batch =  300] train_perplexity =    10.33, train_loss =  2.34, learning_rate = 5.00000000


[batch =  400] train_perplexity =    10.51, train_loss =  2.35, learning_rate = 5.00000000


[batch =  500] train_perplexity =    10.49, train_loss =  2.35, learning_rate = 5.00000000


[batch =  600] train_perplexity =    10.38, train_loss =  2.34, learning_rate = 5.00000000


[batch =  700] train_perplexity =    10.40, train_loss =  2.34, learning_rate = 5.00000000


[batch =  800] train_perplexity =    10.53, train_loss =  2.35, learning_rate = 5.00000000


[batch =  900] train_perplexity =    10.41, train_loss =  2.34, learning_rate = 5.00000000


[batch = 1000] train_perplexity =    10.52, train_loss =  2.35, learning_rate = 5.00000000


[batch = 1100] train_perplexity =    10.58, train_loss =  2.36, learning_rate = 5.00000000


[batch = 1200] train_perplexity =    10.53, train_loss =  2.35, learning_rate = 5.00000000


[batch = 1300] train_perplexity =    10.49, train_loss =  2.35, learning_rate = 5.00000000


[batch = 1400] train_perplexity =    10.62, train_loss =  2.36, learning_rate = 5.00000000


[batch = 1500] train_perplexity =    10.28, train_loss =  2.33, learning_rate = 5.00000000


[batch = 1600] train_perplexity =    10.44, train_loss =  2.35, learning_rate = 5.00000000


[batch = 1700] train_perplexity =    10.31, train_loss =  2.33, learning_rate = 5.00000000


[batch = 1800] train_perplexity =    10.34, train_loss =  2.34, learning_rate = 5.00000000


[batch = 1900] train_perplexity =    10.55, train_loss =  2.36, learning_rate = 5.00000000


[batch = 2000] train_perplexity =    10.67, train_loss =  2.37, learning_rate = 5.00000000


[batch = 2100] train_perplexity =    10.51, train_loss =  2.35, learning_rate = 5.00000000


[batch = 2200] train_perplexity =    10.49, train_loss =  2.35, learning_rate = 5.00000000


[batch = 2300] train_perplexity =    10.61, train_loss =  2.36, learning_rate = 5.00000000


[batch = 2400] train_perplexity =    10.42, train_loss =  2.34, learning_rate = 5.00000000


[batch = 2500] train_perplexity =    10.44, train_loss =  2.35, learning_rate = 5.00000000


[batch = 2600] train_perplexity =    10.46, train_loss =  2.35, learning_rate = 5.00000000


[batch = 2700] train_perplexity =    10.40, train_loss =  2.34, learning_rate = 5.00000000


[batch = 2800] train_perplexity =    10.43, train_loss =  2.34, learning_rate = 5.00000000


[batch = 2900] train_perplexity =    10.40, train_loss =  2.34, learning_rate = 5.00000000


[batch = 3000] train_perplexity =    10.31, train_loss =  2.33, learning_rate = 5.00000000


[batch = 3100] train_perplexity =    10.41, train_loss =  2.34, learning_rate = 5.00000000


[batch = 3200] train_perplexity =    10.49, train_loss =  2.35, learning_rate = 5.00000000


[batch = 3300] train_perplexity =    10.52, train_loss =  2.35, learning_rate = 5.00000000


[batch = 3400] train_perplexity =    10.33, train_loss =  2.34, learning_rate = 5.00000000


[batch = 3500] train_perplexity =    10.29, train_loss =  2.33, learning_rate = 5.00000000


[batch = 3600] train_perplexity =    10.23, train_loss =  2.33, learning_rate = 5.00000000


[batch = 3700] train_perplexity =    10.34, train_loss =  2.34, learning_rate = 5.00000000


[batch = 3800] train_perplexity =    10.17, train_loss =  2.32, learning_rate = 5.00000000


[batch = 3900] train_perplexity =    10.11, train_loss =  2.31, learning_rate = 5.00000000


[batch = 4000] train_perplexity =    10.12, train_loss =  2.31, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     9.98, train_loss =  2.30, learning_rate = 5.00000000


[batch = 4200] train_perplexity =    10.08, train_loss =  2.31, learning_rate = 5.00000000


[batch = 4300] train_perplexity =    10.12, train_loss =  2.31, learning_rate = 5.00000000


[batch = 4400] train_perplexity =    10.11, train_loss =  2.31, learning_rate = 5.00000000


[batch = 4500] train_perplexity =    10.06, train_loss =  2.31, learning_rate = 5.00000000


[batch = 4600] train_perplexity =    10.22, train_loss =  2.32, learning_rate = 5.00000000


[batch = 4700] train_perplexity =    10.15, train_loss =  2.32, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     9.96, train_loss =  2.30, learning_rate = 5.00000000


[batch = 4900] train_perplexity =    10.19, train_loss =  2.32, learning_rate = 5.00000000


[batch = 5000] train_perplexity =    10.14, train_loss =  2.32, learning_rate = 5.00000000


[batch = 5100] train_perplexity =    10.12, train_loss =  2.31, learning_rate = 5.00000000


[batch = 5200] train_perplexity =    10.28, train_loss =  2.33, learning_rate = 5.00000000


[batch = 5300] train_perplexity =    10.35, train_loss =  2.34, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     9.86, train_loss =  2.29, learning_rate = 5.00000000


[batch = 5500] train_perplexity =    10.02, train_loss =  2.30, learning_rate = 5.00000000


[batch = 5600] train_perplexity =    10.14, train_loss =  2.32, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     9.91, train_loss =  2.29, learning_rate = 5.00000000


[batch = 5800] train_perplexity =    10.08, train_loss =  2.31, learning_rate = 5.00000000


[batch = 5900] train_perplexity =    10.06, train_loss =  2.31, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     9.98, train_loss =  2.30, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     9.99, train_loss =  2.30, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     9.98, train_loss =  2.30, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     9.81, train_loss =  2.28, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     9.81, train_loss =  2.28, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     9.67, train_loss =  2.27, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     9.94, train_loss =  2.30, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     9.87, train_loss =  2.29, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     9.81, train_loss =  2.28, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     9.80, train_loss =  2.28, learning_rate = 5.00000000


[epoch =   4] validation_perplexity =     8.74, validation_loss =  2.17

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   4] min_validation_perplexity =     8.74, min_validation_loss =  2.17


[batch =  100] train_perplexity =    10.08, train_loss =  2.31, learning_rate = 5.00000000


[batch =  200] train_perplexity =     9.63, train_loss =  2.26, learning_rate = 5.00000000


[batch =  300] train_perplexity =     9.54, train_loss =  2.26, learning_rate = 5.00000000


[batch =  400] train_perplexity =     9.62, train_loss =  2.26, learning_rate = 5.00000000


[batch =  500] train_perplexity =     9.56, train_loss =  2.26, learning_rate = 5.00000000


[batch =  600] train_perplexity =     9.33, train_loss =  2.23, learning_rate = 5.00000000


[batch =  700] train_perplexity =     9.51, train_loss =  2.25, learning_rate = 5.00000000


[batch =  800] train_perplexity =     9.63, train_loss =  2.27, learning_rate = 5.00000000


[batch =  900] train_perplexity =     9.53, train_loss =  2.25, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     9.63, train_loss =  2.26, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     9.72, train_loss =  2.27, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     9.71, train_loss =  2.27, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     9.75, train_loss =  2.28, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     9.83, train_loss =  2.29, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     9.53, train_loss =  2.25, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     9.67, train_loss =  2.27, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     9.61, train_loss =  2.26, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     9.58, train_loss =  2.26, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     9.82, train_loss =  2.28, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     9.94, train_loss =  2.30, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     9.77, train_loss =  2.28, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     9.74, train_loss =  2.28, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     9.83, train_loss =  2.29, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     9.68, train_loss =  2.27, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     9.76, train_loss =  2.28, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     9.74, train_loss =  2.28, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     9.74, train_loss =  2.28, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     9.55, train_loss =  2.26, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     9.72, train_loss =  2.27, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     9.56, train_loss =  2.26, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     9.76, train_loss =  2.28, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     9.72, train_loss =  2.27, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     9.74, train_loss =  2.28, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     9.56, train_loss =  2.26, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     9.47, train_loss =  2.25, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     9.58, train_loss =  2.26, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     9.58, train_loss =  2.26, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     9.51, train_loss =  2.25, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     9.42, train_loss =  2.24, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     9.55, train_loss =  2.26, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     9.32, train_loss =  2.23, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     9.51, train_loss =  2.25, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     9.48, train_loss =  2.25, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     9.56, train_loss =  2.26, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     9.44, train_loss =  2.25, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     9.51, train_loss =  2.25, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     9.53, train_loss =  2.25, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     9.36, train_loss =  2.24, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     9.58, train_loss =  2.26, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     9.52, train_loss =  2.25, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     9.58, train_loss =  2.26, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     9.69, train_loss =  2.27, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     9.66, train_loss =  2.27, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     9.27, train_loss =  2.23, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     9.40, train_loss =  2.24, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     9.50, train_loss =  2.25, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     9.40, train_loss =  2.24, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     9.43, train_loss =  2.24, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     9.44, train_loss =  2.25, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     9.50, train_loss =  2.25, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     9.40, train_loss =  2.24, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     9.46, train_loss =  2.25, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     9.29, train_loss =  2.23, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     9.34, train_loss =  2.23, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     9.11, train_loss =  2.21, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     9.45, train_loss =  2.25, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     9.34, train_loss =  2.23, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     9.43, train_loss =  2.24, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     9.32, train_loss =  2.23, learning_rate = 5.00000000


[epoch =   5] validation_perplexity =     7.90, validation_loss =  2.07

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   5] min_validation_perplexity =     7.90, min_validation_loss =  2.07


[batch =  100] train_perplexity =     9.58, train_loss =  2.26, learning_rate = 5.00000000


[batch =  200] train_perplexity =     9.15, train_loss =  2.21, learning_rate = 5.00000000


[batch =  300] train_perplexity =     9.12, train_loss =  2.21, learning_rate = 5.00000000


[batch =  400] train_perplexity =     9.10, train_loss =  2.21, learning_rate = 5.00000000


[batch =  500] train_perplexity =     9.07, train_loss =  2.20, learning_rate = 5.00000000


[batch =  600] train_perplexity =     8.91, train_loss =  2.19, learning_rate = 5.00000000


[batch =  700] train_perplexity =     9.09, train_loss =  2.21, learning_rate = 5.00000000


[batch =  800] train_perplexity =     9.23, train_loss =  2.22, learning_rate = 5.00000000


[batch =  900] train_perplexity =     9.16, train_loss =  2.22, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     9.28, train_loss =  2.23, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     9.42, train_loss =  2.24, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     9.25, train_loss =  2.22, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     9.29, train_loss =  2.23, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     9.37, train_loss =  2.24, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     9.12, train_loss =  2.21, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     9.35, train_loss =  2.24, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     9.15, train_loss =  2.21, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     9.21, train_loss =  2.22, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     9.31, train_loss =  2.23, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     9.51, train_loss =  2.25, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     9.38, train_loss =  2.24, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     9.42, train_loss =  2.24, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     9.54, train_loss =  2.26, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     9.30, train_loss =  2.23, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     9.28, train_loss =  2.23, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     9.31, train_loss =  2.23, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     9.25, train_loss =  2.22, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     9.11, train_loss =  2.21, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     9.25, train_loss =  2.22, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     9.10, train_loss =  2.21, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     9.36, train_loss =  2.24, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     9.41, train_loss =  2.24, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     9.33, train_loss =  2.23, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     9.13, train_loss =  2.21, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     9.18, train_loss =  2.22, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     9.24, train_loss =  2.22, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     9.27, train_loss =  2.23, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     9.15, train_loss =  2.21, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     9.04, train_loss =  2.20, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     9.15, train_loss =  2.21, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     8.95, train_loss =  2.19, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     9.08, train_loss =  2.21, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     9.11, train_loss =  2.21, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     9.10, train_loss =  2.21, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     9.04, train_loss =  2.20, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     9.10, train_loss =  2.21, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     9.13, train_loss =  2.21, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     8.98, train_loss =  2.19, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     9.05, train_loss =  2.20, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     9.15, train_loss =  2.21, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     9.15, train_loss =  2.21, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     9.20, train_loss =  2.22, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     9.20, train_loss =  2.22, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     8.82, train_loss =  2.18, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     9.13, train_loss =  2.21, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     9.17, train_loss =  2.22, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     9.04, train_loss =  2.20, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     9.14, train_loss =  2.21, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     9.12, train_loss =  2.21, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     9.05, train_loss =  2.20, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     9.04, train_loss =  2.20, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     9.03, train_loss =  2.20, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     8.90, train_loss =  2.19, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     8.96, train_loss =  2.19, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     8.78, train_loss =  2.17, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     9.10, train_loss =  2.21, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     8.96, train_loss =  2.19, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     9.09, train_loss =  2.21, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     9.02, train_loss =  2.20, learning_rate = 5.00000000


[epoch =   6] validation_perplexity =     7.71, validation_loss =  2.04

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   6] min_validation_perplexity =     7.71, min_validation_loss =  2.04


[batch =  100] train_perplexity =     9.39, train_loss =  2.24, learning_rate = 5.00000000


[batch =  200] train_perplexity =     8.83, train_loss =  2.18, learning_rate = 5.00000000


[batch =  300] train_perplexity =     8.81, train_loss =  2.18, learning_rate = 5.00000000


[batch =  400] train_perplexity =     8.83, train_loss =  2.18, learning_rate = 5.00000000


[batch =  500] train_perplexity =     8.75, train_loss =  2.17, learning_rate = 5.00000000


[batch =  600] train_perplexity =     8.61, train_loss =  2.15, learning_rate = 5.00000000


[batch =  700] train_perplexity =     8.66, train_loss =  2.16, learning_rate = 5.00000000


[batch =  800] train_perplexity =     8.83, train_loss =  2.18, learning_rate = 5.00000000


[batch =  900] train_perplexity =     8.82, train_loss =  2.18, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     8.89, train_loss =  2.19, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     9.04, train_loss =  2.20, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     8.92, train_loss =  2.19, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     8.88, train_loss =  2.18, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     8.98, train_loss =  2.19, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     8.69, train_loss =  2.16, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     8.83, train_loss =  2.18, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     8.68, train_loss =  2.16, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     8.73, train_loss =  2.17, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     8.86, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     9.04, train_loss =  2.20, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     8.85, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     8.88, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     8.99, train_loss =  2.20, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     8.79, train_loss =  2.17, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     8.87, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     8.99, train_loss =  2.20, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     8.88, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     8.78, train_loss =  2.17, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     8.98, train_loss =  2.20, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     8.83, train_loss =  2.18, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     8.94, train_loss =  2.19, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     9.05, train_loss =  2.20, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     8.95, train_loss =  2.19, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     8.82, train_loss =  2.18, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     8.86, train_loss =  2.18, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     8.98, train_loss =  2.19, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     8.97, train_loss =  2.19, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     8.86, train_loss =  2.18, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     8.77, train_loss =  2.17, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     8.92, train_loss =  2.19, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     8.64, train_loss =  2.16, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     8.81, train_loss =  2.18, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     8.73, train_loss =  2.17, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     8.82, train_loss =  2.18, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     8.75, train_loss =  2.17, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     8.78, train_loss =  2.17, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     8.78, train_loss =  2.17, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     8.71, train_loss =  2.16, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     8.86, train_loss =  2.18, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     8.88, train_loss =  2.18, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     8.81, train_loss =  2.18, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     8.91, train_loss =  2.19, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     8.93, train_loss =  2.19, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     8.60, train_loss =  2.15, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     8.85, train_loss =  2.18, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     8.90, train_loss =  2.19, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     8.59, train_loss =  2.15, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     8.79, train_loss =  2.17, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     8.74, train_loss =  2.17, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     8.78, train_loss =  2.17, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     8.76, train_loss =  2.17, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     8.80, train_loss =  2.17, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     8.67, train_loss =  2.16, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     8.68, train_loss =  2.16, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     8.49, train_loss =  2.14, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     8.81, train_loss =  2.18, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     8.70, train_loss =  2.16, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     8.78, train_loss =  2.17, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     8.83, train_loss =  2.18, learning_rate = 5.00000000


[epoch =   7] validation_perplexity =     7.38, validation_loss =  2.00

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   7] min_validation_perplexity =     7.38, min_validation_loss =  2.00


[batch =  100] train_perplexity =     9.09, train_loss =  2.21, learning_rate = 5.00000000


[batch =  200] train_perplexity =     8.66, train_loss =  2.16, learning_rate = 5.00000000


[batch =  300] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch =  400] train_perplexity =     8.57, train_loss =  2.15, learning_rate = 5.00000000


[batch =  500] train_perplexity =     8.52, train_loss =  2.14, learning_rate = 5.00000000


[batch =  600] train_perplexity =     8.37, train_loss =  2.12, learning_rate = 5.00000000


[batch =  700] train_perplexity =     8.52, train_loss =  2.14, learning_rate = 5.00000000


[batch =  800] train_perplexity =     8.62, train_loss =  2.15, learning_rate = 5.00000000


[batch =  900] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     8.61, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     8.74, train_loss =  2.17, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     8.62, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     8.67, train_loss =  2.16, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     8.85, train_loss =  2.18, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     8.70, train_loss =  2.16, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     8.56, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     8.68, train_loss =  2.16, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     8.89, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     8.75, train_loss =  2.17, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     8.77, train_loss =  2.17, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     8.88, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     8.77, train_loss =  2.17, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     8.78, train_loss =  2.17, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     8.88, train_loss =  2.18, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     8.79, train_loss =  2.17, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     8.63, train_loss =  2.16, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     8.76, train_loss =  2.17, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     8.67, train_loss =  2.16, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     8.91, train_loss =  2.19, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     9.05, train_loss =  2.20, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     8.87, train_loss =  2.18, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     8.66, train_loss =  2.16, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     8.64, train_loss =  2.16, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     8.75, train_loss =  2.17, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     8.75, train_loss =  2.17, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     8.64, train_loss =  2.16, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     8.66, train_loss =  2.16, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     8.41, train_loss =  2.13, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     8.52, train_loss =  2.14, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     8.47, train_loss =  2.14, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     8.57, train_loss =  2.15, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     8.51, train_loss =  2.14, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     8.65, train_loss =  2.16, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     8.49, train_loss =  2.14, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     8.60, train_loss =  2.15, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     8.60, train_loss =  2.15, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     8.65, train_loss =  2.16, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     8.60, train_loss =  2.15, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     8.64, train_loss =  2.16, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     8.27, train_loss =  2.11, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     8.51, train_loss =  2.14, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     8.54, train_loss =  2.14, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     8.36, train_loss =  2.12, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     8.44, train_loss =  2.13, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     8.53, train_loss =  2.14, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     8.56, train_loss =  2.15, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     8.61, train_loss =  2.15, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     8.53, train_loss =  2.14, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     8.39, train_loss =  2.13, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     8.43, train_loss =  2.13, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     8.24, train_loss =  2.11, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     8.44, train_loss =  2.13, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     8.54, train_loss =  2.14, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[epoch =   8] validation_perplexity =     7.25, validation_loss =  1.98

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   8] min_validation_perplexity =     7.25, min_validation_loss =  1.98


[batch =  100] train_perplexity =     8.99, train_loss =  2.20, learning_rate = 5.00000000


[batch =  200] train_perplexity =     8.70, train_loss =  2.16, learning_rate = 5.00000000


[batch =  300] train_perplexity =     8.62, train_loss =  2.15, learning_rate = 5.00000000


[batch =  400] train_perplexity =     8.62, train_loss =  2.15, learning_rate = 5.00000000


[batch =  500] train_perplexity =     8.47, train_loss =  2.14, learning_rate = 5.00000000


[batch =  600] train_perplexity =     8.31, train_loss =  2.12, learning_rate = 5.00000000


[batch =  700] train_perplexity =     8.39, train_loss =  2.13, learning_rate = 5.00000000


[batch =  800] train_perplexity =     8.57, train_loss =  2.15, learning_rate = 5.00000000


[batch =  900] train_perplexity =     8.46, train_loss =  2.13, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     8.61, train_loss =  2.15, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     8.47, train_loss =  2.14, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     8.50, train_loss =  2.14, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     8.65, train_loss =  2.16, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     8.35, train_loss =  2.12, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     8.47, train_loss =  2.14, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     8.35, train_loss =  2.12, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     8.29, train_loss =  2.11, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     8.42, train_loss =  2.13, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     8.59, train_loss =  2.15, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     8.44, train_loss =  2.13, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     8.51, train_loss =  2.14, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     8.71, train_loss =  2.16, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     8.44, train_loss =  2.13, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     8.53, train_loss =  2.14, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     8.48, train_loss =  2.14, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     8.45, train_loss =  2.13, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     8.35, train_loss =  2.12, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     8.44, train_loss =  2.13, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     8.31, train_loss =  2.12, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     8.50, train_loss =  2.14, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     8.55, train_loss =  2.15, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     8.46, train_loss =  2.14, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     8.26, train_loss =  2.11, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     8.23, train_loss =  2.11, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     8.32, train_loss =  2.12, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     8.37, train_loss =  2.12, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     8.31, train_loss =  2.12, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     8.24, train_loss =  2.11, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     8.33, train_loss =  2.12, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     8.07, train_loss =  2.09, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     8.24, train_loss =  2.11, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     8.20, train_loss =  2.10, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     8.28, train_loss =  2.11, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     8.24, train_loss =  2.11, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     8.35, train_loss =  2.12, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     8.31, train_loss =  2.12, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     8.16, train_loss =  2.10, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     8.37, train_loss =  2.12, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     8.30, train_loss =  2.12, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     8.29, train_loss =  2.12, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     8.37, train_loss =  2.12, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     8.40, train_loss =  2.13, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     8.02, train_loss =  2.08, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     8.16, train_loss =  2.10, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     8.26, train_loss =  2.11, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     8.04, train_loss =  2.08, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     8.18, train_loss =  2.10, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     8.27, train_loss =  2.11, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     8.29, train_loss =  2.12, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     8.19, train_loss =  2.10, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     8.16, train_loss =  2.10, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     8.17, train_loss =  2.10, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     8.17, train_loss =  2.10, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.99, train_loss =  2.08, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     8.31, train_loss =  2.12, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     8.06, train_loss =  2.09, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     8.17, train_loss =  2.10, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     8.25, train_loss =  2.11, learning_rate = 5.00000000


[epoch =   9] validation_perplexity =     6.95, validation_loss =  1.94

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =   9] min_validation_perplexity =     6.95, min_validation_loss =  1.94


[batch =  100] train_perplexity =     8.69, train_loss =  2.16, learning_rate = 5.00000000


[batch =  200] train_perplexity =     8.18, train_loss =  2.10, learning_rate = 5.00000000


[batch =  300] train_perplexity =     8.14, train_loss =  2.10, learning_rate = 5.00000000


[batch =  400] train_perplexity =     8.07, train_loss =  2.09, learning_rate = 5.00000000


[batch =  500] train_perplexity =     7.99, train_loss =  2.08, learning_rate = 5.00000000


[batch =  600] train_perplexity =     7.83, train_loss =  2.06, learning_rate = 5.00000000


[batch =  700] train_perplexity =     7.87, train_loss =  2.06, learning_rate = 5.00000000


[batch =  800] train_perplexity =     8.06, train_loss =  2.09, learning_rate = 5.00000000


[batch =  900] train_perplexity =     8.04, train_loss =  2.08, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     8.12, train_loss =  2.09, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     8.24, train_loss =  2.11, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     8.10, train_loss =  2.09, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     8.04, train_loss =  2.08, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     8.17, train_loss =  2.10, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     7.88, train_loss =  2.06, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     8.08, train_loss =  2.09, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     7.95, train_loss =  2.07, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     7.97, train_loss =  2.08, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     8.06, train_loss =  2.09, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     8.26, train_loss =  2.11, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     8.10, train_loss =  2.09, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     8.09, train_loss =  2.09, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     8.30, train_loss =  2.12, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     8.08, train_loss =  2.09, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     8.20, train_loss =  2.10, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     8.23, train_loss =  2.11, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     8.16, train_loss =  2.10, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     8.00, train_loss =  2.08, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     8.11, train_loss =  2.09, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     7.98, train_loss =  2.08, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     8.23, train_loss =  2.11, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     8.33, train_loss =  2.12, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     8.23, train_loss =  2.11, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     8.04, train_loss =  2.08, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     7.98, train_loss =  2.08, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     8.07, train_loss =  2.09, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     8.09, train_loss =  2.09, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     8.03, train_loss =  2.08, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     7.90, train_loss =  2.07, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     7.99, train_loss =  2.08, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     7.77, train_loss =  2.05, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     7.91, train_loss =  2.07, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     7.98, train_loss =  2.08, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     7.93, train_loss =  2.07, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     7.99, train_loss =  2.08, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     8.05, train_loss =  2.09, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     7.90, train_loss =  2.07, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     8.03, train_loss =  2.08, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     8.05, train_loss =  2.09, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     8.05, train_loss =  2.09, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     8.07, train_loss =  2.09, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     8.13, train_loss =  2.10, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     7.79, train_loss =  2.05, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     7.92, train_loss =  2.07, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     8.01, train_loss =  2.08, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     7.71, train_loss =  2.04, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     7.98, train_loss =  2.08, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     8.00, train_loss =  2.08, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     7.92, train_loss =  2.07, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     7.86, train_loss =  2.06, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     7.86, train_loss =  2.06, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     7.82, train_loss =  2.06, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     7.97, train_loss =  2.08, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     7.84, train_loss =  2.06, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     7.97, train_loss =  2.08, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     8.09, train_loss =  2.09, learning_rate = 5.00000000


[epoch =  10] validation_perplexity =     6.78, validation_loss =  1.91

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  10] min_validation_perplexity =     6.78, min_validation_loss =  1.91


[batch =  100] train_perplexity =     8.47, train_loss =  2.14, learning_rate = 5.00000000


[batch =  200] train_perplexity =     8.02, train_loss =  2.08, learning_rate = 5.00000000


[batch =  300] train_perplexity =     7.91, train_loss =  2.07, learning_rate = 5.00000000


[batch =  400] train_perplexity =     7.84, train_loss =  2.06, learning_rate = 5.00000000


[batch =  500] train_perplexity =     7.79, train_loss =  2.05, learning_rate = 5.00000000


[batch =  600] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch =  700] train_perplexity =     7.65, train_loss =  2.03, learning_rate = 5.00000000


[batch =  800] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch =  900] train_perplexity =     7.80, train_loss =  2.05, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     7.92, train_loss =  2.07, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     8.04, train_loss =  2.08, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     7.87, train_loss =  2.06, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     7.88, train_loss =  2.06, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     7.97, train_loss =  2.08, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     7.76, train_loss =  2.05, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     7.73, train_loss =  2.05, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     7.78, train_loss =  2.05, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     7.86, train_loss =  2.06, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     8.07, train_loss =  2.09, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     7.79, train_loss =  2.05, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     7.87, train_loss =  2.06, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     8.09, train_loss =  2.09, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     7.91, train_loss =  2.07, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     8.02, train_loss =  2.08, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     8.00, train_loss =  2.08, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     7.91, train_loss =  2.07, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     7.83, train_loss =  2.06, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     7.75, train_loss =  2.05, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     7.95, train_loss =  2.07, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     8.07, train_loss =  2.09, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     7.96, train_loss =  2.07, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     7.77, train_loss =  2.05, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     7.80, train_loss =  2.05, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     7.85, train_loss =  2.06, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     7.85, train_loss =  2.06, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     7.73, train_loss =  2.04, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     7.85, train_loss =  2.06, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     7.65, train_loss =  2.04, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     7.80, train_loss =  2.05, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     7.78, train_loss =  2.05, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     7.78, train_loss =  2.05, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     7.77, train_loss =  2.05, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     7.82, train_loss =  2.06, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     7.92, train_loss =  2.07, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     7.94, train_loss =  2.07, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     7.95, train_loss =  2.07, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     7.74, train_loss =  2.05, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     7.83, train_loss =  2.06, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     7.74, train_loss =  2.05, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     7.80, train_loss =  2.05, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     7.84, train_loss =  2.06, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     7.77, train_loss =  2.05, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     7.70, train_loss =  2.04, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     7.71, train_loss =  2.04, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     7.74, train_loss =  2.05, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.47, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     7.81, train_loss =  2.06, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     7.67, train_loss =  2.04, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     7.68, train_loss =  2.04, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     7.82, train_loss =  2.06, learning_rate = 5.00000000


[epoch =  11] validation_perplexity =     6.65, validation_loss =  1.90

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  11] min_validation_perplexity =     6.65, min_validation_loss =  1.90


[batch =  100] train_perplexity =     8.18, train_loss =  2.10, learning_rate = 5.00000000


[batch =  200] train_perplexity =     7.80, train_loss =  2.05, learning_rate = 5.00000000


[batch =  300] train_perplexity =     7.68, train_loss =  2.04, learning_rate = 5.00000000


[batch =  400] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch =  500] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch =  600] train_perplexity =     7.35, train_loss =  1.99, learning_rate = 5.00000000


[batch =  700] train_perplexity =     7.42, train_loss =  2.00, learning_rate = 5.00000000


[batch =  800] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch =  900] train_perplexity =     7.61, train_loss =  2.03, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     7.77, train_loss =  2.05, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     7.89, train_loss =  2.07, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     7.70, train_loss =  2.04, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     7.78, train_loss =  2.05, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     7.83, train_loss =  2.06, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     7.55, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     7.65, train_loss =  2.03, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     7.55, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     7.68, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     7.81, train_loss =  2.05, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     7.64, train_loss =  2.03, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     7.67, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     7.90, train_loss =  2.07, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     7.68, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     7.77, train_loss =  2.05, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     7.80, train_loss =  2.05, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     7.78, train_loss =  2.05, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     7.67, train_loss =  2.04, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     7.79, train_loss =  2.05, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     7.91, train_loss =  2.07, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     7.83, train_loss =  2.06, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     7.65, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     7.73, train_loss =  2.04, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     7.60, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     7.68, train_loss =  2.04, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     7.43, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     7.69, train_loss =  2.04, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     7.58, train_loss =  2.03, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     7.69, train_loss =  2.04, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     7.71, train_loss =  2.04, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     7.74, train_loss =  2.05, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     7.83, train_loss =  2.06, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     7.76, train_loss =  2.05, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     7.47, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     7.71, train_loss =  2.04, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     7.58, train_loss =  2.03, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     7.57, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     7.65, train_loss =  2.03, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[epoch =  12] validation_perplexity =     6.61, validation_loss =  1.89

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  12] min_validation_perplexity =     6.61, min_validation_loss =  1.89


[batch =  100] train_perplexity =     7.95, train_loss =  2.07, learning_rate = 5.00000000


[batch =  200] train_perplexity =     7.61, train_loss =  2.03, learning_rate = 5.00000000


[batch =  300] train_perplexity =     7.55, train_loss =  2.02, learning_rate = 5.00000000


[batch =  400] train_perplexity =     7.47, train_loss =  2.01, learning_rate = 5.00000000


[batch =  500] train_perplexity =     7.32, train_loss =  1.99, learning_rate = 5.00000000


[batch =  600] train_perplexity =     7.27, train_loss =  1.98, learning_rate = 5.00000000


[batch =  700] train_perplexity =     7.25, train_loss =  1.98, learning_rate = 5.00000000


[batch =  800] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch =  900] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     7.67, train_loss =  2.04, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     7.73, train_loss =  2.04, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     7.47, train_loss =  2.01, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     7.75, train_loss =  2.05, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     7.70, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     7.77, train_loss =  2.05, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     7.67, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     7.55, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     7.75, train_loss =  2.05, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     7.81, train_loss =  2.06, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     7.73, train_loss =  2.05, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     7.36, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     7.46, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     7.57, train_loss =  2.02, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     7.58, train_loss =  2.03, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     7.65, train_loss =  2.04, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     7.68, train_loss =  2.04, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     7.55, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     7.29, train_loss =  1.99, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     7.37, train_loss =  2.00, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     7.47, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     7.43, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.26, train_loss =  1.98, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     7.58, train_loss =  2.03, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[epoch =  13] validation_perplexity =     6.47, validation_loss =  1.87

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  13] min_validation_perplexity =     6.47, min_validation_loss =  1.87


[batch =  100] train_perplexity =     8.03, train_loss =  2.08, learning_rate = 5.00000000


[batch =  200] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch =  300] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch =  400] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch =  500] train_perplexity =     7.33, train_loss =  1.99, learning_rate = 5.00000000


[batch =  600] train_perplexity =     7.20, train_loss =  1.97, learning_rate = 5.00000000


[batch =  700] train_perplexity =     7.27, train_loss =  1.98, learning_rate = 5.00000000


[batch =  800] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch =  900] train_perplexity =     7.37, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     7.57, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     7.69, train_loss =  2.04, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     7.57, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     7.36, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     7.38, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     7.51, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     7.70, train_loss =  2.04, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     7.61, train_loss =  2.03, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     7.63, train_loss =  2.03, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     7.35, train_loss =  1.99, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     7.66, train_loss =  2.04, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     7.75, train_loss =  2.05, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     7.61, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     7.50, train_loss =  2.01, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     7.58, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     7.46, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     7.24, train_loss =  1.98, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     7.39, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     7.42, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     7.50, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     7.50, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     7.57, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     7.31, train_loss =  1.99, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     7.31, train_loss =  1.99, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     7.69, train_loss =  2.04, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     7.46, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     7.48, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     7.44, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.20, train_loss =  1.97, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     7.42, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[epoch =  14] validation_perplexity =     6.20, validation_loss =  1.82

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  14] min_validation_perplexity =     6.20, min_validation_loss =  1.82


[batch =  100] train_perplexity =     7.84, train_loss =  2.06, learning_rate = 5.00000000


[batch =  200] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch =  300] train_perplexity =     7.30, train_loss =  1.99, learning_rate = 5.00000000


[batch =  400] train_perplexity =     7.26, train_loss =  1.98, learning_rate = 5.00000000


[batch =  500] train_perplexity =     7.12, train_loss =  1.96, learning_rate = 5.00000000


[batch =  600] train_perplexity =     7.03, train_loss =  1.95, learning_rate = 5.00000000


[batch =  700] train_perplexity =     7.09, train_loss =  1.96, learning_rate = 5.00000000


[batch =  800] train_perplexity =     7.37, train_loss =  2.00, learning_rate = 5.00000000


[batch =  900] train_perplexity =     7.28, train_loss =  1.98, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     7.46, train_loss =  2.01, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     7.38, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     7.42, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     7.22, train_loss =  1.98, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     7.36, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     7.25, train_loss =  1.98, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     7.24, train_loss =  1.98, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     7.36, train_loss =  2.00, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     7.57, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     7.31, train_loss =  1.99, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     7.52, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     7.39, train_loss =  2.00, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     7.47, train_loss =  2.01, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     7.28, train_loss =  1.98, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     7.65, train_loss =  2.04, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     7.38, train_loss =  2.00, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     7.43, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     7.29, train_loss =  1.99, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     7.38, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     7.39, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     7.43, train_loss =  2.01, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     7.48, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     7.20, train_loss =  1.97, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     7.42, train_loss =  2.00, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     7.14, train_loss =  1.97, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     7.27, train_loss =  1.98, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     7.36, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     7.30, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     7.23, train_loss =  1.98, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     7.27, train_loss =  1.98, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     7.29, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.07, train_loss =  1.96, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     7.32, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     7.23, train_loss =  1.98, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     7.31, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     7.37, train_loss =  2.00, learning_rate = 5.00000000


[epoch =  15] validation_perplexity =     6.09, validation_loss =  1.81

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  15] min_validation_perplexity =     6.09, min_validation_loss =  1.81


[batch =  100] train_perplexity =     7.80, train_loss =  2.05, learning_rate = 5.00000000


[batch =  200] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch =  300] train_perplexity =     7.33, train_loss =  1.99, learning_rate = 5.00000000


[batch =  400] train_perplexity =     7.36, train_loss =  2.00, learning_rate = 5.00000000


[batch =  500] train_perplexity =     7.27, train_loss =  1.98, learning_rate = 5.00000000


[batch =  600] train_perplexity =     7.09, train_loss =  1.96, learning_rate = 5.00000000


[batch =  700] train_perplexity =     7.04, train_loss =  1.95, learning_rate = 5.00000000


[batch =  800] train_perplexity =     7.36, train_loss =  2.00, learning_rate = 5.00000000


[batch =  900] train_perplexity =     7.25, train_loss =  1.98, learning_rate = 5.00000000


[batch = 1000] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 1100] train_perplexity =     7.50, train_loss =  2.02, learning_rate = 5.00000000


[batch = 1200] train_perplexity =     7.35, train_loss =  1.99, learning_rate = 5.00000000


[batch = 1300] train_perplexity =     7.31, train_loss =  1.99, learning_rate = 5.00000000


[batch = 1400] train_perplexity =     7.33, train_loss =  1.99, learning_rate = 5.00000000


[batch = 1500] train_perplexity =     7.17, train_loss =  1.97, learning_rate = 5.00000000


[batch = 1600] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 1700] train_perplexity =     7.18, train_loss =  1.97, learning_rate = 5.00000000


[batch = 1800] train_perplexity =     7.16, train_loss =  1.97, learning_rate = 5.00000000


[batch = 1900] train_perplexity =     7.33, train_loss =  1.99, learning_rate = 5.00000000


[batch = 2000] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2100] train_perplexity =     7.24, train_loss =  1.98, learning_rate = 5.00000000


[batch = 2200] train_perplexity =     7.39, train_loss =  2.00, learning_rate = 5.00000000


[batch = 2300] train_perplexity =     7.59, train_loss =  2.03, learning_rate = 5.00000000


[batch = 2400] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 2500] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 2600] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 2700] train_perplexity =     7.39, train_loss =  2.00, learning_rate = 5.00000000


[batch = 2800] train_perplexity =     7.35, train_loss =  2.00, learning_rate = 5.00000000


[batch = 2900] train_perplexity =     7.43, train_loss =  2.00, learning_rate = 5.00000000


[batch = 3000] train_perplexity =     7.25, train_loss =  1.98, learning_rate = 5.00000000


[batch = 3100] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3200] train_perplexity =     7.62, train_loss =  2.03, learning_rate = 5.00000000


[batch = 3300] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 3400] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 3500] train_perplexity =     7.34, train_loss =  1.99, learning_rate = 5.00000000


[batch = 3600] train_perplexity =     7.39, train_loss =  2.00, learning_rate = 5.00000000


[batch = 3700] train_perplexity =     7.41, train_loss =  2.00, learning_rate = 5.00000000


[batch = 3800] train_perplexity =     7.33, train_loss =  1.99, learning_rate = 5.00000000


[batch = 3900] train_perplexity =     7.30, train_loss =  1.99, learning_rate = 5.00000000


[batch = 4000] train_perplexity =     7.35, train_loss =  1.99, learning_rate = 5.00000000


[batch = 4100] train_perplexity =     7.06, train_loss =  1.95, learning_rate = 5.00000000


[batch = 4200] train_perplexity =     7.14, train_loss =  1.97, learning_rate = 5.00000000


[batch = 4300] train_perplexity =     7.16, train_loss =  1.97, learning_rate = 5.00000000


[batch = 4400] train_perplexity =     7.26, train_loss =  1.98, learning_rate = 5.00000000


[batch = 4500] train_perplexity =     7.26, train_loss =  1.98, learning_rate = 5.00000000


[batch = 4600] train_perplexity =     7.24, train_loss =  1.98, learning_rate = 5.00000000


[batch = 4700] train_perplexity =     7.32, train_loss =  1.99, learning_rate = 5.00000000


[batch = 4800] train_perplexity =     7.25, train_loss =  1.98, learning_rate = 5.00000000


[batch = 4900] train_perplexity =     7.31, train_loss =  1.99, learning_rate = 5.00000000


[batch = 5000] train_perplexity =     7.38, train_loss =  2.00, learning_rate = 5.00000000


[batch = 5100] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5200] train_perplexity =     7.48, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5300] train_perplexity =     7.57, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5400] train_perplexity =     7.33, train_loss =  1.99, learning_rate = 5.00000000


[batch = 5500] train_perplexity =     7.49, train_loss =  2.01, learning_rate = 5.00000000


[batch = 5600] train_perplexity =     7.56, train_loss =  2.02, learning_rate = 5.00000000


[batch = 5700] train_perplexity =     7.25, train_loss =  1.98, learning_rate = 5.00000000


[batch = 5800] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 5900] train_perplexity =     7.54, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6000] train_perplexity =     7.53, train_loss =  2.02, learning_rate = 5.00000000


[batch = 6100] train_perplexity =     7.45, train_loss =  2.01, learning_rate = 5.00000000


[batch = 6200] train_perplexity =     7.35, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6300] train_perplexity =     7.32, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6400] train_perplexity =     7.28, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6500] train_perplexity =     7.09, train_loss =  1.96, learning_rate = 5.00000000


[batch = 6600] train_perplexity =     7.39, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6700] train_perplexity =     7.33, train_loss =  1.99, learning_rate = 5.00000000


[batch = 6800] train_perplexity =     7.40, train_loss =  2.00, learning_rate = 5.00000000


[batch = 6900] train_perplexity =     7.43, train_loss =  2.01, learning_rate = 5.00000000


[epoch =  16] validation_perplexity =     6.33, validation_loss =  1.85

[epoch =  16] annealing learning_rate = 1.25000000

[batch =  100] train_perplexity =     7.42, train_loss =  2.00, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.93, train_loss =  1.94, learning_rate = 1.25000000


[batch =  300] train_perplexity =     6.81, train_loss =  1.92, learning_rate = 1.25000000


[batch =  400] train_perplexity =     6.66, train_loss =  1.90, learning_rate = 1.25000000


[batch =  500] train_perplexity =     6.55, train_loss =  1.88, learning_rate = 1.25000000


[batch =  600] train_perplexity =     6.44, train_loss =  1.86, learning_rate = 1.25000000


[batch =  700] train_perplexity =     6.46, train_loss =  1.87, learning_rate = 1.25000000


[batch =  800] train_perplexity =     6.72, train_loss =  1.91, learning_rate = 1.25000000


[batch =  900] train_perplexity =     6.61, train_loss =  1.89, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.71, train_loss =  1.90, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.83, train_loss =  1.92, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     6.72, train_loss =  1.91, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.71, train_loss =  1.90, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.70, train_loss =  1.90, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     6.50, train_loss =  1.87, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     6.62, train_loss =  1.89, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     6.47, train_loss =  1.87, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     6.52, train_loss =  1.87, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     6.63, train_loss =  1.89, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.72, train_loss =  1.90, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     6.52, train_loss =  1.88, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     6.58, train_loss =  1.88, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.75, train_loss =  1.91, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     6.60, train_loss =  1.89, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.70, train_loss =  1.90, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.70, train_loss =  1.90, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.60, train_loss =  1.89, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     6.51, train_loss =  1.87, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     6.56, train_loss =  1.88, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     6.45, train_loss =  1.86, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.69, train_loss =  1.90, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.78, train_loss =  1.91, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.67, train_loss =  1.90, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     6.50, train_loss =  1.87, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     6.56, train_loss =  1.88, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     6.55, train_loss =  1.88, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     6.60, train_loss =  1.89, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     6.52, train_loss =  1.87, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     6.42, train_loss =  1.86, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     6.57, train_loss =  1.88, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     6.30, train_loss =  1.84, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     6.39, train_loss =  1.85, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     6.40, train_loss =  1.86, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     6.47, train_loss =  1.87, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     6.46, train_loss =  1.87, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     6.43, train_loss =  1.86, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     6.47, train_loss =  1.87, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     6.41, train_loss =  1.86, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     6.53, train_loss =  1.88, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     6.53, train_loss =  1.88, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.55, train_loss =  1.88, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.59, train_loss =  1.89, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.56, train_loss =  1.88, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     6.32, train_loss =  1.84, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     6.49, train_loss =  1.87, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     6.53, train_loss =  1.88, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     6.38, train_loss =  1.85, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     6.46, train_loss =  1.87, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     6.49, train_loss =  1.87, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     6.42, train_loss =  1.86, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     6.34, train_loss =  1.85, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     6.32, train_loss =  1.84, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     6.33, train_loss =  1.85, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     6.18, train_loss =  1.82, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     6.43, train_loss =  1.86, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     6.33, train_loss =  1.85, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     6.36, train_loss =  1.85, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     6.44, train_loss =  1.86, learning_rate = 1.25000000


[epoch =  17] validation_perplexity =     5.52, validation_loss =  1.71

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  17] min_validation_perplexity =     5.52, min_validation_loss =  1.71


[batch =  100] train_perplexity =     6.92, train_loss =  1.93, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.48, train_loss =  1.87, learning_rate = 1.25000000


[batch =  300] train_perplexity =     6.39, train_loss =  1.86, learning_rate = 1.25000000


[batch =  400] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch =  500] train_perplexity =     6.18, train_loss =  1.82, learning_rate = 1.25000000


[batch =  600] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch =  700] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch =  800] train_perplexity =     6.39, train_loss =  1.85, learning_rate = 1.25000000


[batch =  900] train_perplexity =     6.27, train_loss =  1.84, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.43, train_loss =  1.86, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.49, train_loss =  1.87, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     6.43, train_loss =  1.86, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.41, train_loss =  1.86, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.43, train_loss =  1.86, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     6.34, train_loss =  1.85, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     6.20, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     6.24, train_loss =  1.83, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     6.35, train_loss =  1.85, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.48, train_loss =  1.87, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     6.36, train_loss =  1.85, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.56, train_loss =  1.88, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     6.39, train_loss =  1.85, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.48, train_loss =  1.87, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.45, train_loss =  1.86, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.39, train_loss =  1.86, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     6.31, train_loss =  1.84, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     6.35, train_loss =  1.85, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     6.25, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.46, train_loss =  1.87, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.56, train_loss =  1.88, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.44, train_loss =  1.86, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     6.31, train_loss =  1.84, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     6.30, train_loss =  1.84, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     6.37, train_loss =  1.85, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     6.21, train_loss =  1.83, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     6.31, train_loss =  1.84, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     6.21, train_loss =  1.83, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     6.27, train_loss =  1.84, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     6.32, train_loss =  1.84, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     6.32, train_loss =  1.84, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.36, train_loss =  1.85, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.39, train_loss =  1.85, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.39, train_loss =  1.86, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     6.25, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     6.31, train_loss =  1.84, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     6.20, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     6.31, train_loss =  1.84, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     6.33, train_loss =  1.84, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     6.21, train_loss =  1.83, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     6.17, train_loss =  1.82, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     6.18, train_loss =  1.82, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     6.28, train_loss =  1.84, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     6.19, train_loss =  1.82, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     6.20, train_loss =  1.83, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     6.31, train_loss =  1.84, learning_rate = 1.25000000


[epoch =  18] validation_perplexity =     5.38, validation_loss =  1.68

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  18] min_validation_perplexity =     5.38, min_validation_loss =  1.68


[batch =  100] train_perplexity =     6.67, train_loss =  1.90, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch =  300] train_perplexity =     6.23, train_loss =  1.83, learning_rate = 1.25000000


[batch =  400] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch =  500] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch =  800] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch =  900] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.32, train_loss =  1.84, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.32, train_loss =  1.84, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     6.28, train_loss =  1.84, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.27, train_loss =  1.84, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     6.17, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     6.23, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.35, train_loss =  1.85, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     6.14, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     6.23, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.38, train_loss =  1.85, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     6.24, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.38, train_loss =  1.85, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.38, train_loss =  1.85, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.25, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     6.19, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     6.24, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.33, train_loss =  1.85, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.44, train_loss =  1.86, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.35, train_loss =  1.85, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     6.17, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     6.19, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     6.25, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     6.20, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     6.23, train_loss =  1.83, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     6.18, train_loss =  1.82, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     6.14, train_loss =  1.82, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     6.19, train_loss =  1.82, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     6.23, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.23, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.28, train_loss =  1.84, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     6.06, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     6.14, train_loss =  1.82, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     6.20, train_loss =  1.82, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.96, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     6.17, train_loss =  1.82, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     6.08, train_loss =  1.81, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     6.21, train_loss =  1.83, learning_rate = 1.25000000


[epoch =  19] validation_perplexity =     5.31, validation_loss =  1.67

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  19] min_validation_perplexity =     5.31, min_validation_loss =  1.67


[batch =  100] train_perplexity =     6.61, train_loss =  1.89, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.23, train_loss =  1.83, learning_rate = 1.25000000


[batch =  300] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch =  400] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch =  800] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch =  900] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.24, train_loss =  1.83, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     6.18, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.28, train_loss =  1.84, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     6.08, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.30, train_loss =  1.84, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     6.14, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.27, train_loss =  1.84, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.24, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.19, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.24, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.35, train_loss =  1.85, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     6.06, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     6.21, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     6.02, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     6.14, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.24, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     6.02, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[epoch =  20] validation_perplexity =     5.24, validation_loss =  1.66

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  20] min_validation_perplexity =     5.24, min_validation_loss =  1.66


[batch =  100] train_perplexity =     6.52, train_loss =  1.87, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch =  300] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch =  800] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.20, train_loss =  1.83, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.96, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.21, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.25, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.19, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.18, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.29, train_loss =  1.84, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     6.08, train_loss =  1.81, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.14, train_loss =  1.82, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     6.08, train_loss =  1.81, learning_rate = 1.25000000


[epoch =  21] validation_perplexity =     5.18, validation_loss =  1.65

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  21] min_validation_perplexity =     5.18, min_validation_loss =  1.65


[batch =  100] train_perplexity =     6.45, train_loss =  1.86, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch =  300] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch =  800] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.17, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.22, train_loss =  1.83, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     6.06, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.14, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.96, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     6.02, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[epoch =  22] validation_perplexity =     5.12, validation_loss =  1.63

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  22] min_validation_perplexity =     5.12, min_validation_loss =  1.63


[batch =  100] train_perplexity =     6.43, train_loss =  1.86, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch =  800] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     6.02, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.96, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.13, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.19, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.96, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.96, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.06, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     6.02, train_loss =  1.79, learning_rate = 1.25000000


[epoch =  23] validation_perplexity =     5.07, validation_loss =  1.62

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  23] min_validation_perplexity =     5.07, min_validation_loss =  1.62


[batch =  100] train_perplexity =     6.40, train_loss =  1.86, learning_rate = 1.25000000


[batch =  200] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.07, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.14, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     6.10, train_loss =  1.81, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.16, train_loss =  1.82, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.96, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.96, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     6.03, train_loss =  1.80, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[epoch =  24] validation_perplexity =     5.03, validation_loss =  1.62

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  24] min_validation_perplexity =     5.03, min_validation_loss =  1.62


[batch =  100] train_perplexity =     6.32, train_loss =  1.84, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.78, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     6.01, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.05, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.78, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.11, train_loss =  1.81, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     6.00, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.84, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.84, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.96, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.96, train_loss =  1.79, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.78, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.79, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[epoch =  25] validation_perplexity =     4.99, validation_loss =  1.61

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  25] min_validation_perplexity =     4.99, min_validation_loss =  1.61


[batch =  100] train_perplexity =     6.30, train_loss =  1.84, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.56, train_loss =  1.71, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.97, train_loss =  1.79, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     6.02, train_loss =  1.80, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.99, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.08, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.96, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.93, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[epoch =  26] validation_perplexity =     4.95, validation_loss =  1.60

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  26] min_validation_perplexity =     4.95, min_validation_loss =  1.60


[batch =  100] train_perplexity =     6.26, train_loss =  1.83, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.91, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.84, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     6.04, train_loss =  1.80, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.94, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.89, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.79, train_loss =  1.76, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[epoch =  27] validation_perplexity =     4.93, validation_loss =  1.59

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  27] min_validation_perplexity =     4.93, min_validation_loss =  1.59


[batch =  100] train_perplexity =     6.20, train_loss =  1.83, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.92, train_loss =  1.78, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.95, train_loss =  1.78, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.79, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.61, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[epoch =  28] validation_perplexity =     4.87, validation_loss =  1.58

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  28] min_validation_perplexity =     4.87, min_validation_loss =  1.58


[batch =  100] train_perplexity =     6.15, train_loss =  1.82, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.84, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.79, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.96, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.83, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.78, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.61, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[epoch =  29] validation_perplexity =     4.85, validation_loss =  1.58

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  29] min_validation_perplexity =     4.85, min_validation_loss =  1.58


[batch =  100] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.79, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.82, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.56, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.78, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.90, train_loss =  1.78, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.56, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.79, train_loss =  1.76, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[epoch =  30] validation_perplexity =     4.81, validation_loss =  1.57

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  30] min_validation_perplexity =     4.81, min_validation_loss =  1.57


[batch =  100] train_perplexity =     6.12, train_loss =  1.81, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.78, train_loss =  1.76, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.39, train_loss =  1.69, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.45, train_loss =  1.69, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.85, train_loss =  1.77, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.73, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.73, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[epoch =  31] validation_perplexity =     4.80, validation_loss =  1.57

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  31] min_validation_perplexity =     4.80, min_validation_loss =  1.57


[batch =  100] train_perplexity =     6.17, train_loss =  1.82, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.81, train_loss =  1.76, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.79, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.88, train_loss =  1.77, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.76, train_loss =  1.75, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[epoch =  32] validation_perplexity =     4.76, validation_loss =  1.56

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  32] min_validation_perplexity =     4.76, min_validation_loss =  1.56


[batch =  100] train_perplexity =     6.09, train_loss =  1.81, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.84, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[epoch =  33] validation_perplexity =     4.73, validation_loss =  1.55

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  33] min_validation_perplexity =     4.73, min_validation_loss =  1.55


[batch =  100] train_perplexity =     5.98, train_loss =  1.79, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.56, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.56, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.67, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.56, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[epoch =  34] validation_perplexity =     4.70, validation_loss =  1.55

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  34] min_validation_perplexity =     4.70, min_validation_loss =  1.55


[batch =  100] train_perplexity =     5.96, train_loss =  1.79, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.67, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.68, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.72, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.74, train_loss =  1.75, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.65, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.45, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[epoch =  35] validation_perplexity =     4.68, validation_loss =  1.54

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  35] min_validation_perplexity =     4.68, min_validation_loss =  1.54


[batch =  100] train_perplexity =     5.96, train_loss =  1.79, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.69, train_loss =  1.74, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.71, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[epoch =  36] validation_perplexity =     4.65, validation_loss =  1.54

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  36] min_validation_perplexity =     4.65, min_validation_loss =  1.54


[batch =  100] train_perplexity =     5.90, train_loss =  1.77, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.56, train_loss =  1.71, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.70, train_loss =  1.74, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[epoch =  37] validation_perplexity =     4.64, validation_loss =  1.53

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  37] min_validation_perplexity =     4.64, min_validation_loss =  1.53


[batch =  100] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[epoch =  38] validation_perplexity =     4.62, validation_loss =  1.53

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  38] min_validation_perplexity =     4.62, min_validation_loss =  1.53


[batch =  100] train_perplexity =     5.87, train_loss =  1.77, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.45, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.39, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[epoch =  39] validation_perplexity =     4.60, validation_loss =  1.53

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  39] min_validation_perplexity =     4.60, min_validation_loss =  1.53


[batch =  100] train_perplexity =     5.86, train_loss =  1.77, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.57, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[epoch =  40] validation_perplexity =     4.56, validation_loss =  1.52

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  40] min_validation_perplexity =     4.56, min_validation_loss =  1.52


[batch =  100] train_perplexity =     5.80, train_loss =  1.76, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.39, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.29, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.62, train_loss =  1.73, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.39, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[epoch =  41] validation_perplexity =     4.56, validation_loss =  1.52

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  41] min_validation_perplexity =     4.56, min_validation_loss =  1.52


[batch =  100] train_perplexity =     5.78, train_loss =  1.75, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.50, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.52, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.48, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.59, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[epoch =  42] validation_perplexity =     4.52, validation_loss =  1.51

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  42] min_validation_perplexity =     4.52, min_validation_loss =  1.51


[batch =  100] train_perplexity =     5.77, train_loss =  1.75, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.54, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[epoch =  43] validation_perplexity =     4.51, validation_loss =  1.51

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  43] min_validation_perplexity =     4.51, min_validation_loss =  1.51


[batch =  100] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.45, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.56, train_loss =  1.72, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[epoch =  44] validation_perplexity =     4.50, validation_loss =  1.50

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  44] min_validation_perplexity =     4.50, min_validation_loss =  1.50


[batch =  100] train_perplexity =     5.75, train_loss =  1.75, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.34, train_loss =  1.67, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.43, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.50, train_loss =  1.71, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[epoch =  45] validation_perplexity =     4.48, validation_loss =  1.50

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  45] min_validation_perplexity =     4.48, min_validation_loss =  1.50


[batch =  100] train_perplexity =     5.66, train_loss =  1.73, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch =  600] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.39, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.42, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.37, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.47, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[epoch =  46] validation_perplexity =     4.46, validation_loss =  1.50

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  46] min_validation_perplexity =     4.46, min_validation_loss =  1.50


[batch =  100] train_perplexity =     5.64, train_loss =  1.73, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch =  700] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.13, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.41, train_loss =  1.69, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.46, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.13, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[epoch =  47] validation_perplexity =     4.45, validation_loss =  1.49

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  47] min_validation_perplexity =     4.45, min_validation_loss =  1.49


[batch =  100] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.45, train_loss =  1.70, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[epoch =  48] validation_perplexity =     4.43, validation_loss =  1.49

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  48] min_validation_perplexity =     4.43, min_validation_loss =  1.49


[batch =  100] train_perplexity =     5.63, train_loss =  1.73, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.36, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.44, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[epoch =  49] validation_perplexity =     4.41, validation_loss =  1.48

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  49] min_validation_perplexity =     4.41, min_validation_loss =  1.48


[batch =  100] train_perplexity =     5.60, train_loss =  1.72, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch =  500] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.08, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.34, train_loss =  1.68, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[epoch =  50] validation_perplexity =     4.41, validation_loss =  1.48

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  50] min_validation_perplexity =     4.41, min_validation_loss =  1.48


[batch =  100] train_perplexity =     5.58, train_loss =  1.72, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch =  400] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch =  500] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.13, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.13, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.08, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[epoch =  51] validation_perplexity =     4.39, validation_loss =  1.48

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  51] min_validation_perplexity =     4.39, min_validation_loss =  1.48


[batch =  100] train_perplexity =     5.61, train_loss =  1.72, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch =  400] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch =  500] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.40, train_loss =  1.69, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.08, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[epoch =  52] validation_perplexity =     4.38, validation_loss =  1.48

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  52] min_validation_perplexity =     4.38, min_validation_loss =  1.48


[batch =  100] train_perplexity =     5.53, train_loss =  1.71, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch =  400] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch =  500] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.08, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.29, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.35, train_loss =  1.68, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[epoch =  53] validation_perplexity =     4.36, validation_loss =  1.47

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  53] min_validation_perplexity =     4.36, min_validation_loss =  1.47


[batch =  100] train_perplexity =     5.55, train_loss =  1.71, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch =  400] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 1.25000000


[batch =  500] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.13, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.13, train_loss =  1.63, learning_rate = 1.25000000


[epoch =  54] validation_perplexity =     4.34, validation_loss =  1.47

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  54] min_validation_perplexity =     4.34, min_validation_loss =  1.47


[batch =  100] train_perplexity =     5.51, train_loss =  1.71, learning_rate = 1.25000000


[batch =  200] train_perplexity =     5.15, train_loss =  1.64, learning_rate = 1.25000000


[batch =  300] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch =  400] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 1.25000000


[batch =  500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 1.25000000


[batch =  600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 1.25000000


[batch =  700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 1.25000000


[batch =  800] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch =  900] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 1000] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 1.25000000


[batch = 1200] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1300] train_perplexity =     5.13, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1400] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 1500] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch = 1600] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 1700] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 1.25000000


[batch = 1800] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 1900] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 2000] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2100] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch = 2200] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2300] train_perplexity =     5.27, train_loss =  1.66, learning_rate = 1.25000000


[batch = 2400] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2500] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2600] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 2700] train_perplexity =     5.17, train_loss =  1.64, learning_rate = 1.25000000


[batch = 2800] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 1.25000000


[batch = 2900] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3000] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch = 3100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3200] train_perplexity =     5.30, train_loss =  1.67, learning_rate = 1.25000000


[batch = 3300] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 3400] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 3500] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3600] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3700] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 3800] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 3900] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4000] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 4100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 1.25000000


[batch = 4200] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4300] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch = 4400] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4500] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4600] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4700] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4800] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 1.25000000


[batch = 4900] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5000] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5100] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5200] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 1.25000000


[batch = 5300] train_perplexity =     5.16, train_loss =  1.64, learning_rate = 1.25000000


[batch = 5400] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 5500] train_perplexity =     5.08, train_loss =  1.62, learning_rate = 1.25000000


[batch = 5600] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 1.25000000


[batch = 5700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 1.25000000


[batch = 5800] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 1.25000000


[batch = 5900] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[batch = 6000] train_perplexity =     5.08, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6100] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6200] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 1.25000000


[batch = 6300] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6400] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6500] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 1.25000000


[batch = 6600] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 1.25000000


[batch = 6700] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6800] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 1.25000000


[batch = 6900] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 1.25000000


[epoch =  55] validation_perplexity =     4.34, validation_loss =  1.47

[epoch =  55] annealing learning_rate = 0.31250000

[batch =  100] train_perplexity =     5.49, train_loss =  1.70, learning_rate = 0.31250000


[batch =  200] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 0.31250000


[batch =  300] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch =  800] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.18, train_loss =  1.64, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.98, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[epoch =  56] validation_perplexity =     4.22, validation_loss =  1.44

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  56] min_validation_perplexity =     4.22, min_validation_loss =  1.44


[batch =  100] train_perplexity =     5.38, train_loss =  1.68, learning_rate = 0.31250000


[batch =  200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[epoch =  57] validation_perplexity =     4.20, validation_loss =  1.44

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  57] min_validation_perplexity =     4.20, min_validation_loss =  1.44


[batch =  100] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 0.31250000


[batch =  200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.09, train_loss =  1.63, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.13, train_loss =  1.64, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[epoch =  58] validation_perplexity =     4.20, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  58] min_validation_perplexity =     4.20, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.14, train_loss =  1.64, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[epoch =  59] validation_perplexity =     4.19, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  59] min_validation_perplexity =     4.19, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.32, train_loss =  1.67, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[epoch =  60] validation_perplexity =     4.19, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  60] min_validation_perplexity =     4.19, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.33, train_loss =  1.67, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.12, train_loss =  1.63, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[epoch =  61] validation_perplexity =     4.18, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  61] min_validation_perplexity =     4.18, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.31, train_loss =  1.67, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[epoch =  62] validation_perplexity =     4.17, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  62] min_validation_perplexity =     4.17, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     4.98, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.11, train_loss =  1.63, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[epoch =  63] validation_perplexity =     4.17, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  63] min_validation_perplexity =     4.17, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     4.98, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[epoch =  64] validation_perplexity =     4.16, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  64] min_validation_perplexity =     4.16, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.29, train_loss =  1.67, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.07, train_loss =  1.62, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[epoch =  65] validation_perplexity =     4.16, validation_loss =  1.43

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  65] min_validation_perplexity =     4.16, min_validation_loss =  1.43


[batch =  100] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.08, train_loss =  1.63, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[epoch =  66] validation_perplexity =     4.15, validation_loss =  1.42

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  66] min_validation_perplexity =     4.15, min_validation_loss =  1.42


[batch =  100] train_perplexity =     5.26, train_loss =  1.66, learning_rate = 0.31250000


[batch =  200] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.31250000


[batch =  300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch =  400] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.31250000


[batch =  500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.31250000


[batch =  600] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.31250000


[batch =  700] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.31250000


[batch =  800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch =  900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.31250000


[batch = 1000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.31250000


[batch = 1200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1300] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 1400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 1500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1700] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 1900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2000] train_perplexity =     4.98, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2100] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 2200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.31250000


[batch = 2300] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.31250000


[batch = 2400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2500] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2600] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.31250000


[batch = 2700] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 2800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 2900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 3100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3200] train_perplexity =     5.10, train_loss =  1.63, learning_rate = 0.31250000


[batch = 3300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.31250000


[batch = 3400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.31250000


[batch = 3500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3700] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 3800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 3900] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4000] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4100] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.31250000


[batch = 4200] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 4300] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 4700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 4900] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5000] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5200] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5300] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.31250000


[batch = 5400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5500] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 5700] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.31250000


[batch = 5800] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 5900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.31250000


[batch = 6100] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6200] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6300] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.31250000


[batch = 6600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.31250000


[batch = 6700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.31250000


[batch = 6900] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.31250000


[epoch =  67] validation_perplexity =     4.15, validation_loss =  1.42

[epoch =  67] annealing learning_rate = 0.07812500

[batch =  100] train_perplexity =     5.28, train_loss =  1.66, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.98, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.99, train_loss =  1.61, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  68] validation_perplexity =     4.12, validation_loss =  1.42

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  68] min_validation_perplexity =     4.12, min_validation_loss =  1.42


[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.06, train_loss =  1.62, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  69] validation_perplexity =     4.12, validation_loss =  1.42

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  69] min_validation_perplexity =     4.12, min_validation_loss =  1.42


[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  70] validation_perplexity =     4.12, validation_loss =  1.42

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  70] min_validation_perplexity =     4.12, min_validation_loss =  1.42


[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  71] validation_perplexity =     4.11, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  71] min_validation_perplexity =     4.11, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  72] validation_perplexity =     4.11, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  72] min_validation_perplexity =     4.11, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  73] validation_perplexity =     4.11, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  73] min_validation_perplexity =     4.11, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  74] validation_perplexity =     4.11, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  74] min_validation_perplexity =     4.11, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.07812500


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.07812500


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.07812500


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.07812500


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.07812500


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.07812500


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch =  900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.07812500


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.07812500


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.07812500


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 2000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.07812500


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.07812500


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.07812500


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.07812500


[batch = 3500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.07812500


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.07812500


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.07812500


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.07812500


[batch = 4900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.07812500


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.07812500


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.07812500


[batch = 5700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.07812500


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.07812500


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.07812500


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.07812500


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.07812500


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.07812500


[epoch =  75] validation_perplexity =     4.11, validation_loss =  1.41

[epoch =  75] annealing learning_rate = 0.01953125

[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.01953125


[batch =  200] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.01953125


[batch =  300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch =  500] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.01953125


[batch =  600] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.01953125


[batch =  700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.01953125


[batch =  800] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.01953125


[batch =  900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.01953125


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.01953125


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2700] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.01953125


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.01953125


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.01953125


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.01953125


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.01953125


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.01953125


[epoch =  76] validation_perplexity =     4.10, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  76] min_validation_perplexity =     4.10, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.01953125


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.01953125


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.01953125


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.01953125


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.01953125


[batch =  800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.01953125


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.01953125


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.01953125


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.01953125


[batch = 2800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.01953125


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.01953125


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.01953125


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.01953125


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.01953125


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.01953125


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.01953125


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[epoch =  77] validation_perplexity =     4.10, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  77] min_validation_perplexity =     4.10, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 0.01953125


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.01953125


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.01953125


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.01953125


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.01953125


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 1100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.01953125


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[batch = 1300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.01953125


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.01953125


[batch = 1500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 2200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.01953125


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.01953125


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.01953125


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.01953125


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.01953125


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[epoch =  78] validation_perplexity =     4.10, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  78] min_validation_perplexity =     4.10, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.01953125


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.01953125


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.01953125


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.01953125


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.01953125


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.01953125


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.01953125


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.01953125


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.01953125


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.01953125


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.01953125


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4100] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.01953125


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 5300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.01953125


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.01953125


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[epoch =  79] validation_perplexity =     4.10, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  79] min_validation_perplexity =     4.10, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.01953125


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.01953125


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.01953125


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.01953125


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.01953125


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.01953125


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.01953125


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.01953125


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.01953125


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.01953125


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 3100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.01953125


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.01953125


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.01953125


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.01953125


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.01953125


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[epoch =  80] validation_perplexity =     4.10, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  80] min_validation_perplexity =     4.10, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.01953125


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.01953125


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.01953125


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.01953125


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.01953125


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.01953125


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.01953125


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.01953125


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.01953125


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.01953125


[batch = 2400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 2500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.01953125


[batch = 2700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.01953125


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.01953125


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.01953125


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.01953125


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.01953125


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.01953125


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.01953125


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.01953125


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.01953125


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.01953125


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.01953125


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.01953125


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.01953125


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.01953125


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.01953125


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.01953125


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.01953125


[epoch =  81] validation_perplexity =     4.10, validation_loss =  1.41

[epoch =  81] annealing learning_rate = 0.00488281

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00488281


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00488281


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00488281


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00488281


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00488281


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00488281


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00488281


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00488281


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00488281


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00488281


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00488281


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00488281


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00488281


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00488281


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00488281


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00488281


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00488281


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00488281


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00488281


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00488281


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00488281


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00488281


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00488281


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00488281


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00488281


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[epoch =  82] validation_perplexity =     4.10, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  82] min_validation_perplexity =     4.10, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00488281


[batch =  200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00488281


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00488281


[batch =  500] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00488281


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00488281


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00488281


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00488281


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00488281


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00488281


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00488281


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00488281


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00488281


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00488281


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00488281


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00488281


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00488281


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00488281


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00488281


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00488281


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00488281


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00488281


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00488281


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00488281


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00488281


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00488281


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5700] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00488281


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00488281


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00488281


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00488281


[epoch =  83] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  83] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00488281


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00488281


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00488281


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00488281


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00488281


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00488281


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00488281


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00488281


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00488281


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00488281


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 1900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00488281


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00488281


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00488281


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00488281


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00488281


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00488281


[batch = 2700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00488281


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00488281


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00488281


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00488281


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00488281


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00488281


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00488281


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00488281


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00488281


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00488281


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00488281


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00488281


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00488281


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00488281


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00488281


[batch = 6000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00488281


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00488281


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00488281


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00488281


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00488281


[epoch =  84] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  84] annealing learning_rate = 0.00122070

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00122070


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00122070


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00122070


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00122070


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00122070


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00122070


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00122070


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00122070


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00122070


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00122070


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 5500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00122070


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00122070


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00122070


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00122070


[epoch =  85] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  85] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00122070


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00122070


[batch =  300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00122070


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00122070


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00122070


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00122070


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00122070


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00122070


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00122070


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00122070


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00122070


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00122070


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00122070


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00122070


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00122070


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00122070


[epoch =  86] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  86] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00122070


[batch =  200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00122070


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00122070


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00122070


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00122070


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00122070


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00122070


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00122070


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00122070


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00122070


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00122070


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00122070


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00122070


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00122070


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00122070


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00122070


[epoch =  87] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  87] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00122070


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00122070


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00122070


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00122070


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00122070


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00122070


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00122070


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00122070


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00122070


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00122070


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00122070


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00122070


[batch = 5500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00122070


[batch = 5800] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00122070


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00122070


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[epoch =  88] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  88] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00122070


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00122070


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00122070


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00122070


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00122070


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00122070


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00122070


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00122070


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00122070


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00122070


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00122070


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3000] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00122070


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00122070


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00122070


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00122070


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4100] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00122070


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00122070


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00122070


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00122070


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00122070


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00122070


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00122070


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00122070


[batch = 5700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00122070


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00122070


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00122070


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00122070


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00122070


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00122070


[batch = 6900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00122070


[epoch =  89] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  89] annealing learning_rate = 0.00030518

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00030518


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00030518


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00030518


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00030518


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00030518


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00030518


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00030518


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3000] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00030518


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00030518


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3900] train_perplexity =     4.74, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00030518


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00030518


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00030518


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[epoch =  90] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  90] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00030518


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00030518


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00030518


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00030518


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 1100] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.00030518


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 1400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00030518


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00030518


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00030518


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00030518


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00030518


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 3500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00030518


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00030518


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00030518


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5700] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00030518


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00030518


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00030518


[epoch =  91] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  91] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00030518


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00030518


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00030518


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00030518


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00030518


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00030518


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00030518


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00030518


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00030518


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00030518


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00030518


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00030518


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00030518


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00030518


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00030518


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00030518


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00030518


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00030518


[batch = 6700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00030518


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[epoch =  92] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  92] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00030518


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00030518


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00030518


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00030518


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00030518


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00030518


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00030518


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00030518


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00030518


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00030518


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00030518


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00030518


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00030518


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00030518


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00030518


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5200] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00030518


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00030518


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00030518


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[epoch =  93] validation_perplexity =     4.09, validation_loss =  1.41

Saved model to 'e200/ptb_char_gru.pt'...
[epoch =  93] min_validation_perplexity =     4.09, min_validation_loss =  1.41


[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.00030518


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00030518


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00030518


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00030518


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00030518


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00030518


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00030518


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00030518


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00030518


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00030518


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00030518


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00030518


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00030518


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00030518


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00030518


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00030518


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00030518


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00030518


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00030518


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00030518


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00030518


[batch = 5700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00030518


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00030518


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00030518


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00030518


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00030518


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00030518


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00030518


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00030518


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00030518


[epoch =  94] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  94] annealing learning_rate = 0.00007629

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00007629


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00007629


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00007629


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00007629


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00007629


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00007629


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00007629


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00007629


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00007629


[batch = 1000] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00007629


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00007629


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00007629


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00007629


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00007629


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00007629


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00007629


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00007629


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00007629


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00007629


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00007629


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00007629


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00007629


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00007629


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00007629


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00007629


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00007629


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00007629


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00007629


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00007629


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00007629


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00007629


[batch = 3200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.00007629


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00007629


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00007629


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00007629


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00007629


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00007629


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00007629


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00007629


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00007629


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00007629


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00007629


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00007629


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00007629


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00007629


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00007629


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00007629


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00007629


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00007629


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00007629


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00007629


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00007629


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00007629


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00007629


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00007629


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00007629


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00007629


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00007629


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00007629


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00007629


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00007629


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00007629


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00007629


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00007629


[batch = 6500] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00007629


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00007629


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00007629


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00007629


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00007629


[epoch =  95] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  95] annealing learning_rate = 0.00001907

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00001907


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00001907


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00001907


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00001907


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00001907


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00001907


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00001907


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00001907


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00001907


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00001907


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00001907


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00001907


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00001907


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00001907


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00001907


[batch = 1600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00001907


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00001907


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00001907


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00001907


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00001907


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00001907


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00001907


[batch = 2300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.00001907


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00001907


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00001907


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00001907


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00001907


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00001907


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00001907


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00001907


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00001907


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00001907


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00001907


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00001907


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00001907


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00001907


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00001907


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00001907


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00001907


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00001907


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00001907


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00001907


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00001907


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00001907


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00001907


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00001907


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00001907


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00001907


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00001907


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00001907


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00001907


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00001907


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00001907


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00001907


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00001907


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00001907


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00001907


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00001907


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00001907


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00001907


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00001907


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00001907


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00001907


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00001907


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00001907


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00001907


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00001907


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00001907


[batch = 6900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00001907


[epoch =  96] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  96] annealing learning_rate = 0.00000477

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000477


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000477


[batch =  300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000477


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000477


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000477


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000477


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000477


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000477


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000477


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000477


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000477


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000477


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000477


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000477


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000477


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000477


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000477


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000477


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000477


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000477


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000477


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000477


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000477


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000477


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000477


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000477


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000477


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000477


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000477


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000477


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000477


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000477


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000477


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000477


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000477


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000477


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000477


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000477


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000477


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000477


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000477


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000477


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000477


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000477


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000477


[batch = 4600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000477


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000477


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000477


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000477


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000477


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000477


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000477


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000477


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000477


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000477


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000477


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000477


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000477


[batch = 5900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000477


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000477


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000477


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000477


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000477


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000477


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000477


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000477


[batch = 6700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000477


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000477


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000477


[epoch =  97] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  97] annealing learning_rate = 0.00000119

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000119


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000119


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000119


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000119


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000119


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000119


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000119


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000119


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000119


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000119


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000119


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000119


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000119


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000119


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000119


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000119


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000119


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000119


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000119


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000119


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000119


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000119


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000119


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000119


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000119


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000119


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000119


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000119


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000119


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000119


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000119


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000119


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000119


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000119


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000119


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000119


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000119


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000119


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000119


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000119


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000119


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000119


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000119


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000119


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000119


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000119


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000119


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000119


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000119


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000119


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000119


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000119


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000119


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000119


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000119


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000119


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000119


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000119


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000119


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000119


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000119


[batch = 6200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000119


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000119


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000119


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000119


[batch = 6600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000119


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000119


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000119


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000119


[epoch =  98] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  98] annealing learning_rate = 0.00000030

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000030


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000030


[batch =  300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000030


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000030


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000030


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000030


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000030


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000030


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000030


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000030


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000030


[batch = 1200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000030


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000030


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000030


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000030


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000030


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000030


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000030


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000030


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000030


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000030


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000030


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000030


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000030


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000030


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000030


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000030


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000030


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000030


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000030


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000030


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.00000030


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000030


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000030


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000030


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000030


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000030


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000030


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000030


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000030


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000030


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000030


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000030


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000030


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000030


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000030


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000030


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000030


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000030


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000030


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000030


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000030


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000030


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000030


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000030


[batch = 5600] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000030


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000030


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000030


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000030


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000030


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000030


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000030


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000030


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000030


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000030


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000030


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000030


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000030


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000030


[epoch =  99] validation_perplexity =     4.09, validation_loss =  1.41

[epoch =  99] annealing learning_rate = 0.00000007

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000007


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000007


[batch =  300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000007


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000007


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000007


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000007


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000007


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000007


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000007


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000007


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000007


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000007


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000007


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000007


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000007


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000007


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000007


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000007


[batch = 1900] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000007


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000007


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000007


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000007


[batch = 2300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.00000007


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000007


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000007


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000007


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000007


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000007


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000007


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000007


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000007


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000007


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000007


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000007


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000007


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000007


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000007


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000007


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000007


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000007


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000007


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000007


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000007


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000007


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000007


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000007


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000007


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000007


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000007


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000007


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000007


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000007


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000007


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000007


[batch = 5500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000007


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000007


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000007


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000007


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000007


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000007


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000007


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000007


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000007


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000007


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000007


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000007


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000007


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000007


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000007


[epoch = 100] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 100] annealing learning_rate = 0.00000002

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000002


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000002


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000002


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000002


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000002


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000002


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000002


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000002


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000002


[batch = 1000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000002


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000002


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000002


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000002


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000002


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000002


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000002


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000002


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000002


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000002


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000002


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000002


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000002


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000002


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000002


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000002


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000002


[batch = 2700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000002


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000002


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000002


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000002


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000002


[batch = 3200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.00000002


[batch = 3300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000002


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000002


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000002


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000002


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000002


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000002


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000002


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000002


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000002


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000002


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000002


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000002


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000002


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000002


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000002


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000002


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000002


[batch = 5000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000002


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000002


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000002


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000002


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000002


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000002


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000002


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000002


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000002


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000002


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000002


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000002


[batch = 6200] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000002


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000002


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000002


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000002


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000002


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000002


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000002


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000002


[epoch = 101] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 101] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 102] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 102] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 103] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 103] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.66, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 104] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 104] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 105] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 105] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 106] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 106] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 107] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 107] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 108] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 108] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 109] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 109] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 110] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 110] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 111] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 111] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 112] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 112] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 113] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 113] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 114] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 114] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 115] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 115] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 116] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 116] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 117] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 117] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 118] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 118] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 119] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 119] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 120] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 120] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 121] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 121] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 122] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 122] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 123] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 123] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.74, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 124] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 124] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 125] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 125] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 126] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 126] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 127] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 127] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 128] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 128] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 129] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 129] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 130] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 130] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 131] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 131] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 132] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 132] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 133] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 133] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 134] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 134] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 135] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 135] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 136] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 136] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 137] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 137] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 138] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 138] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 139] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 139] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 140] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 140] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 141] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 141] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.97, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 142] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 142] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 143] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 143] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 144] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 144] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 145] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 145] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 146] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 146] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 147] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 147] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 148] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 148] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 149] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 149] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 150] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 150] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 151] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 151] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 152] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 152] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 153] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 153] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 154] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 154] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 155] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 155] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.53, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 156] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 156] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 157] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 157] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 158] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 158] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 159] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 159] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 160] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 160] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 161] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 161] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 162] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 162] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 163] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 163] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 164] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 164] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 165] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 165] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 166] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 166] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 167] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 167] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 168] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 168] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 169] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 169] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 170] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 170] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 171] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 171] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 172] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 172] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.05, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 173] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 173] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 174] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 174] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 175] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 175] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 176] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 176] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 177] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 177] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 178] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 178] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 179] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 179] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 180] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 180] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 181] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 181] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 182] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 182] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.54, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 183] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 183] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 184] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 184] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 185] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 185] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 186] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 186] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 187] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 187] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 188] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 188] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 189] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 189] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 190] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 190] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 191] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 191] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.18, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 192] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 192] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.19, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.65, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 193] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 193] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.22, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.00, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 194] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 194] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.25, train_loss =  1.66, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.03, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 195] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 195] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.62, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.96, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.04, train_loss =  1.62, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 196] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 196] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.20, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.55, train_loss =  1.51, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 197] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 197] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.21, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.66, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.01, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 198] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 198] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.24, train_loss =  1.66, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.63, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.56, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.93, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.92, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.93, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.60, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.85, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.88, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.88, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[epoch = 199] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 199] annealing learning_rate = 0.00000000

[batch =  100] train_perplexity =     5.23, train_loss =  1.65, learning_rate = 0.00000000


[batch =  200] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch =  300] train_perplexity =     4.80, train_loss =  1.57, learning_rate = 0.00000000


[batch =  400] train_perplexity =     4.67, train_loss =  1.54, learning_rate = 0.00000000


[batch =  500] train_perplexity =     4.64, train_loss =  1.53, learning_rate = 0.00000000


[batch =  600] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch =  700] train_perplexity =     4.59, train_loss =  1.52, learning_rate = 0.00000000


[batch =  800] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch =  900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 1000] train_perplexity =     4.91, train_loss =  1.59, learning_rate = 0.00000000


[batch = 1100] train_perplexity =     4.94, train_loss =  1.60, learning_rate = 0.00000000


[batch = 1200] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1300] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 1400] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 1500] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1600] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1700] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 1800] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 1900] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2000] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2100] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 2200] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2300] train_perplexity =     4.95, train_loss =  1.60, learning_rate = 0.00000000


[batch = 2400] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 2500] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2600] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 2700] train_perplexity =     4.87, train_loss =  1.58, learning_rate = 0.00000000


[batch = 2800] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 2900] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3000] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 3100] train_perplexity =     4.90, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3200] train_perplexity =     5.02, train_loss =  1.61, learning_rate = 0.00000000


[batch = 3300] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 3400] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 3500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3700] train_perplexity =     4.84, train_loss =  1.58, learning_rate = 0.00000000


[batch = 3800] train_perplexity =     4.78, train_loss =  1.57, learning_rate = 0.00000000


[batch = 3900] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4000] train_perplexity =     4.81, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4100] train_perplexity =     4.61, train_loss =  1.53, learning_rate = 0.00000000


[batch = 4200] train_perplexity =     4.69, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 4400] train_perplexity =     4.74, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4500] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4600] train_perplexity =     4.75, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4700] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 4800] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 4900] train_perplexity =     4.83, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5000] train_perplexity =     4.77, train_loss =  1.56, learning_rate = 0.00000000


[batch = 5100] train_perplexity =     4.86, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5200] train_perplexity =     4.89, train_loss =  1.59, learning_rate = 0.00000000


[batch = 5300] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5400] train_perplexity =     4.68, train_loss =  1.54, learning_rate = 0.00000000


[batch = 5500] train_perplexity =     4.79, train_loss =  1.57, learning_rate = 0.00000000


[batch = 5600] train_perplexity =     4.83, train_loss =  1.58, learning_rate = 0.00000000


[batch = 5700] train_perplexity =     4.58, train_loss =  1.52, learning_rate = 0.00000000


[batch = 5800] train_perplexity =     4.72, train_loss =  1.55, learning_rate = 0.00000000


[batch = 5900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[batch = 6000] train_perplexity =     4.78, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6100] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6200] train_perplexity =     4.70, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6300] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6400] train_perplexity =     4.69, train_loss =  1.54, learning_rate = 0.00000000


[batch = 6500] train_perplexity =     4.57, train_loss =  1.52, learning_rate = 0.00000000


[batch = 6600] train_perplexity =     4.76, train_loss =  1.56, learning_rate = 0.00000000


[batch = 6700] train_perplexity =     4.71, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6800] train_perplexity =     4.73, train_loss =  1.55, learning_rate = 0.00000000


[batch = 6900] train_perplexity =     4.82, train_loss =  1.57, learning_rate = 0.00000000


[epoch = 200] validation_perplexity =     4.09, validation_loss =  1.41

[epoch = 200] annealing learning_rate = 0.00000000
Test validation:

test_perplexity =     4.02, test_loss =  1.39
